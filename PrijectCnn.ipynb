{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b5e815f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gil70\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import signal\n",
    "from scipy.fft import fft, fftfreq\n",
    "import librosa\n",
    "import librosa.display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# הגדרת matplotlib לעברית\n",
    "plt.rcParams['font.family'] = ['Arial Unicode MS', 'Tahoma', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "\n",
    "DATA_PATH = \"data/\"\n",
    "\n",
    "\n",
    "def load_and_prepare_data(data_path_folder):\n",
    "    file_mapping = {\n",
    "        'car_nothing.csv': 'quiet',\n",
    "        'carnew.csv': 'vehicle',\n",
    "        'human_nothing.csv': 'quiet',\n",
    "        'human.csv': 'human'\n",
    "    }\n",
    "    label_encoding = {'quiet': 0, 'vehicle': 1, 'human': 2}\n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "    print(\"Starting data loading...\")\n",
    "    if not os.path.exists(data_path_folder):\n",
    "        print(f\"Data folder {data_path_folder} not found. Please create it and add data files.\")\n",
    "        return np.array([]), np.array([])\n",
    "    for filename, activity_type in file_mapping.items():\n",
    "        filepath = os.path.join(data_path_folder, filename)\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"Error: File not found at {filepath}. Skipping.\")\n",
    "            continue\n",
    "        try:\n",
    "            df = pd.read_csv(filepath, header=None)\n",
    "            if not df.empty and df.shape[1] > 0:\n",
    "                data = df.iloc[:, 0].values\n",
    "                label_code = label_encoding[activity_type]\n",
    "                all_data.extend(data)\n",
    "                all_labels.extend([label_code] * len(data))\n",
    "            else:\n",
    "                print(f\"Warning: File {filename} is empty or has no data columns. Skipping.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filename}: {e}\")\n",
    "    all_data_np = np.array(all_data)\n",
    "    all_labels_np = np.array(all_labels)\n",
    "    if len(all_data_np) > 0:\n",
    "        print(f\"Total data points loaded: {len(all_data_np)}\")\n",
    "    else:\n",
    "        print(\"No data was loaded.\")\n",
    "    return all_data_np, all_labels_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a78aca9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_raw_data(data_dict, labels_dict, window_size_seconds=2, sample_rate=1000):\n",
    "    \"\"\"הכנת נתונים גולמיים עם חלונות זמן\"\"\"\n",
    "    \n",
    "    window_size = window_size_seconds * sample_rate  # 2000 דגימות\n",
    "    \n",
    "    raw_windows = []\n",
    "    labels = []\n",
    "    \n",
    "    # חישוב מספר כולל של חלונות לtqdm\n",
    "    total_windows = 0\n",
    "    for filename, signal_data in data_dict.items():\n",
    "        total_windows += (signal_data.shape[0] - window_size) // (window_size // 2)\n",
    "    \n",
    "    print(f\"🔄 יצירת {total_windows} חלונות של {window_size_seconds} שניות...\")\n",
    "    \n",
    "    with tqdm(total=total_windows, desc=\"עיבוד חלונות גולמיים\") as pbar:\n",
    "        for filename, signal_data in data_dict.items():\n",
    "            label = labels_dict[filename]\n",
    "            \n",
    "            # חלונות עם overlap של 50%\n",
    "            step_size = window_size // 2\n",
    "            \n",
    "            for start_idx in range(0, signal_data.shape[0] - window_size + 1, step_size):\n",
    "                end_idx = start_idx + window_size\n",
    "                window = signal_data[start_idx:end_idx]\n",
    "                \n",
    "                if window.shape[0] == window_size:\n",
    "                    raw_windows.append(window)\n",
    "                    labels.append(label)\n",
    "                \n",
    "                pbar.update(1)\n",
    "                if pbar.n >= total_windows:\n",
    "                    break\n",
    "    \n",
    "    return np.array(raw_windows), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61e8be68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. מודל CNN פשוט לנתונים גולמיים\n",
    "def create_raw_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"מודל CNN לנתונים גולמיים (2D: זמן × חיישנים)\"\"\"\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        # Input layer\n",
    "        layers.Input(shape=input_shape),\n",
    "        \n",
    "        # הוספת dimension channel\n",
    "        layers.Reshape(input_shape + (1,)),\n",
    "        \n",
    "        # CNN layers - רואה דפוסים בזמן ובין חיישנים\n",
    "        layers.Conv2D(16, (5, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 1)),\n",
    "        layers.BatchNormalization(),\n",
    "        \n",
    "        layers.Conv2D(32, (5, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 1)),\n",
    "        layers.BatchNormalization(),\n",
    "        \n",
    "        layers.Conv2D(64, (3, 2), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 1)),\n",
    "        layers.BatchNormalization(),\n",
    "        \n",
    "        layers.Conv2D(128, (3, 2), activation='relu', padding='same'),\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        \n",
    "        # Dense layers\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # Output\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56621788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_raw_1d_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"מודל CNN 1D שמעבד כל חיישן בנפרד ואז מאחד\"\"\"\n",
    "    \n",
    "    # Input\n",
    "    input_layer = layers.Input(shape=input_shape)  # (2000, num_sensors)\n",
    "    \n",
    "    # עיבוד כל חיישן בנפרד\n",
    "    sensor_outputs = []\n",
    "    \n",
    "    for i in range(input_shape[1]):  # עבור כל חיישן\n",
    "        # חילוץ חיישן בודד\n",
    "        sensor_data = layers.Lambda(lambda x, idx=i: x[:, :, idx:idx+1])(input_layer)\n",
    "        \n",
    "        # CNN 1D על החיישן\n",
    "        x = layers.Conv1D(32, 11, activation='relu', padding='same')(sensor_data)\n",
    "        x = layers.MaxPooling1D(2)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Conv1D(64, 7, activation='relu', padding='same')(x)\n",
    "        x = layers.MaxPooling1D(2)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Conv1D(128, 5, activation='relu', padding='same')(x)\n",
    "        x = layers.GlobalAveragePooling1D()(x)\n",
    "        \n",
    "        sensor_outputs.append(x)\n",
    "    \n",
    "    # איחוד כל החיישנים\n",
    "    if len(sensor_outputs) > 1:\n",
    "        combined = layers.Concatenate()(sensor_outputs)\n",
    "    else:\n",
    "        combined = sensor_outputs[0]\n",
    "    \n",
    "    # Dense layers\n",
    "    x = layers.Dense(256, activation='relu')(combined)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Output\n",
    "    output = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = keras.Model(inputs=input_layer, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa523497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. אימון מודל נתונים גולמיים\n",
    "def train_raw_model(model_type='2d'):\n",
    "    \"\"\"אימון מודל על נתונים גולמיים\"\"\"\n",
    "    \n",
    "    print(\"🔄 שלב 1: אימון על נתונים גולמיים\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # טעינת נתונים\n",
    "    data_dict, labels_dict = load_geophone_data()\n",
    "    \n",
    "    if not data_dict:\n",
    "        print(\"❌ לא נמצאו קבצי נתונים!\")\n",
    "        return None\n",
    "    \n",
    "    # הכנת נתונים גולמיים\n",
    "    X_raw, y_raw = prepare_raw_data(data_dict, labels_dict, window_size_seconds=2)\n",
    "    \n",
    "    print(f\"✅ נוצרו {len(X_raw)} חלונות גולמיים\")\n",
    "    print(f\"📊 צורת חלון: {X_raw[0].shape}\")\n",
    "    print(f\"📈 טווח ערכים: {X_raw.min():.4f} עד {X_raw.max():.4f}\")\n",
    "    \n",
    "    # קידוד תוויות\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y_raw)\n",
    "    y_categorical = tf.keras.utils.to_categorical(y_encoded)\n",
    "    \n",
    "    print(f\"🏷️ קטגוריות: {label_encoder.classes_}\")\n",
    "    \n",
    "    # נורמליזציה\n",
    "    X_normalized = (X_raw - X_raw.mean()) / X_raw.std()\n",
    "    \n",
    "    # חלוקת נתונים\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_normalized, y_categorical, \n",
    "        test_size=0.2, random_state=42, stratify=y_encoded\n",
    "    )\n",
    "    \n",
    "    print(f\"📈 אימון: {X_train.shape[0]} דגימות\")\n",
    "    print(f\"📉 בדיקה: {X_test.shape[0]} דגימות\")\n",
    "    \n",
    "    # בניית מודל\n",
    "    print(f\"\\n🏗️ בניית מודל CNN {model_type.upper()}...\")\n",
    "    if model_type == '2d':\n",
    "        model = create_raw_cnn_model(X_train[0].shape, len(label_encoder.classes_))\n",
    "    else:\n",
    "        model = create_raw_1d_cnn_model(X_train[0].shape, len(label_encoder.classes_))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    print(\"📋 סיכום מודל נתונים גולמיים:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "    ]\n",
    "    \n",
    "    # אימון\n",
    "    print(f\"\\n🎯 אימון מודל נתונים גולמיים...\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=32,\n",
    "        epochs=50,\n",
    "        validation_split=0.2,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # הערכה\n",
    "    print(\"\\n📊 הערכת מודל נתונים גולמיים...\")\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"🎯 דיוק מודל גולמי: {test_accuracy:.4f}\")\n",
    "    \n",
    "    # תחזיות\n",
    "    y_pred = model.predict(X_test, verbose=0)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_test_classes = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    print(\"\\n📈 דוח ביצועים - מודל גולמי:\")\n",
    "    print(classification_report(\n",
    "        y_test_classes, y_pred_classes, \n",
    "        target_names=label_encoder.classes_\n",
    "    ))\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'history': history,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'label_encoder': label_encoder,\n",
    "        'predictions': (y_test_classes, y_pred_classes),\n",
    "        'type': 'raw_' + model_type\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
