# Part 0: Setup and Global Configurations
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.utils.class_weight import compute_class_weight
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import glob
import os
import time # For timing epochs
import optuna # For hyperparameter optimization

# For reproducibility
SEED = 42
np.random.seed(SEED)
torch.manual_seed(SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(SEED)

# Define global constants
DATA_PATH = "data/" # Define the path to the data folder
SEQUENCE_LENGTH = 1000  # Sequence length in data points
# LATENT_DIM_AE will be determined by Optuna
LATENT_DIM_GAN = 100    # Latent dimension for the GAN
GAN_TRAIN_EPOCHS = 100 # Reduced for faster example run, GAN is secondary here
GAN_BATCH_SIZE = 32
# AE_TRAIN_EPOCHS will be set for Optuna trials and final training
CLASSIFIER_TRAIN_EPOCHS = 100
CLASSIFIER_BATCH_SIZE = 64

# --- PyTorch Device Setup ---
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# --- Part 1: Data Loading and Preparation ---
print("--- Part 1: Data Loading and Preparation ---")

def load_and_prepare_data(data_path_folder):
    file_mapping = {
        'car_nothing(AVI).csv': 'quiet',
        'carnew(AVI).csv': 'vehicle',
        'human_nothing(AVI).csv': 'quiet',
        'human(AVI).csv': 'human'
    }
    label_encoding = {'quiet': 0, 'vehicle': 1, 'human': 2}
    all_data = []
    all_labels = []

    print("Starting data loading...")
    if not os.path.exists(data_path_folder):
        print(f"Data folder {data_path_folder} not found. Please create it and add data files.")
        return np.array([]), np.array([])

    for filename, activity_type in file_mapping.items():
        filepath = os.path.join(data_path_folder, filename)
        if not os.path.exists(filepath):
            print(f"Error: File not found at {filepath}. Skipping.")
            continue
        try:
            df = pd.read_csv(filepath, header=None)
            if not df.empty and df.shape[1] > 0:
                data = df.iloc[:, 0].values
                print(f"Read file {filename}: {df.shape[0]} samples -> {activity_type}")
                label_code = label_encoding[activity_type]
                all_data.extend(data)
                all_labels.extend([label_code] * len(data))
            else:
                print(f"Warning: File {filename} is empty or has no data columns. Skipping.")
        except Exception as e:
            print(f"Error reading {filename}: {e}")

    print("Data loading finished.")
    all_data_np = np.array(all_data)
    all_labels_np = np.array(all_labels)

    if len(all_data_np) > 0:
        print(f"Total data points loaded: {len(all_data_np)}")
        print(f"Total labels loaded: {len(all_labels_np)}")
        if len(all_labels_np) > 0:
            print(f"Unique categories loaded: {np.unique(all_labels_np)} - {list(label_encoding.keys())}")
            print(f"Label distribution (counts): {np.bincount(all_labels_np)}")
    else:
        print("No data was loaded. Please check the DATA_PATH and ensure CSV files are present.")
    return all_data_np, all_labels_np

X_raw, y_raw = load_and_prepare_data(DATA_PATH)

if len(X_raw) == 0:
    print("No data loaded. Exiting.")
    exit()
else:
    print("Raw data loaded successfully.")

# --- Part 2: Sequence Creation, Normalization, and Data Splitting ---
print("\n--- Part 2: Sequence Creation, Normalization, and Data Splitting ---")

def create_sequences(data, labels, sequence_length):
    sequences = []
    sequence_labels = []
    unique_labels = np.unique(labels)
    for label in unique_labels:
        label_indices = np.where(labels == label)[0]
        label_data = data[label_indices]
        num_sequences_for_label = len(label_data) // sequence_length
        for i in range(num_sequences_for_label):
            start_idx = i * sequence_length
            end_idx = start_idx + sequence_length
            sequences.append(label_data[start_idx:end_idx])
            sequence_labels.append(label)
    return np.array(sequences), np.array(sequence_labels)

X_sequences, y_sequences = create_sequences(X_raw, y_raw, SEQUENCE_LENGTH)

if len(X_sequences) == 0:
    print("No sequences were created. Exiting.")
    exit()

print(f"Created {len(X_sequences)} sequences with length {SEQUENCE_LENGTH}.")

X_train_seq, X_temp_seq, y_train, y_temp = train_test_split(
    X_sequences, y_sequences, test_size=0.3, random_state=SEED, stratify=y_sequences
)
X_val_seq, X_test_seq, y_val, y_test = train_test_split(
    X_temp_seq, y_temp, test_size=0.5, random_state=SEED, stratify=y_temp
)

scaler = StandardScaler()
X_train_flat = X_train_seq.reshape(-1, 1)
X_val_flat = X_val_seq.reshape(-1, 1)
X_test_flat = X_test_seq.reshape(-1, 1)

scaler.fit(X_train_flat)
X_train_normalized_flat = scaler.transform(X_train_flat)
X_val_normalized_flat = scaler.transform(X_val_flat)
X_test_normalized_flat = scaler.transform(X_test_flat)

X_train_normalized = X_train_normalized_flat.reshape(X_train_seq.shape)
X_val_normalized = X_val_normalized_flat.reshape(X_val_seq.shape)
X_test_normalized = X_test_normalized_flat.reshape(X_test_seq.shape)

X_train_reshaped = X_train_normalized[:, np.newaxis, :]
X_val_reshaped = X_val_normalized[:, np.newaxis, :]
X_test_reshaped = X_test_normalized[:, np.newaxis, :]

X_train_tensor = torch.tensor(X_train_reshaped, dtype=torch.float32)
y_train_tensor = torch.tensor(y_train, dtype=torch.long)
X_val_tensor = torch.tensor(X_val_reshaped, dtype=torch.float32)
y_val_tensor = torch.tensor(y_val, dtype=torch.long)
X_test_tensor = torch.tensor(X_test_reshaped, dtype=torch.float32)
y_test_tensor = torch.tensor(y_test, dtype=torch.long)

# DataLoaders for Autoencoder
train_dataset_ae = TensorDataset(X_train_tensor, X_train_tensor)
val_dataset_ae = TensorDataset(X_val_tensor, X_val_tensor)
# Use CLASSIFIER_BATCH_SIZE for AE as well, or define a separate AE_BATCH_SIZE
train_loader_ae = DataLoader(train_dataset_ae, batch_size=CLASSIFIER_BATCH_SIZE, shuffle=True)
val_loader_ae = DataLoader(val_dataset_ae, batch_size=CLASSIFIER_BATCH_SIZE, shuffle=False)

# DataLoaders for Classifier
train_dataset_clf = TensorDataset(X_train_tensor, y_train_tensor)
val_dataset_clf = TensorDataset(X_val_tensor, y_val_tensor)
test_dataset_clf = TensorDataset(X_test_tensor, y_test_tensor)
train_loader_clf = DataLoader(train_dataset_clf, batch_size=CLASSIFIER_BATCH_SIZE, shuffle=True)
val_loader_clf = DataLoader(val_dataset_clf, batch_size=CLASSIFIER_BATCH_SIZE, shuffle=False)
test_loader_clf = DataLoader(test_dataset_clf, batch_size=CLASSIFIER_BATCH_SIZE, shuffle=False)

# DataLoader for GAN
gan_dataset = TensorDataset(X_train_tensor)
gan_loader = DataLoader(gan_dataset, batch_size=GAN_BATCH_SIZE, shuffle=True)

# --- Part 3: Autoencoder Model Definition, Compilation, and Training with Optuna NAS ---
print("\n--- Part 3: Autoencoder Model with Optuna NAS ---")

SEQUENCE_LENGTH_AE = X_train_tensor.shape[2]
INPUT_CHANNELS_AE = X_train_tensor.shape[1]

class Encoder(nn.Module):
    def __init__(self, encoding_dim, dropout_rate, num_filters_1, num_filters_2, num_filters_3):
        super(Encoder, self).__init__()
        self.conv1 = nn.Conv1d(INPUT_CHANNELS_AE, num_filters_1, kernel_size=3, padding='same')
        self.bn1 = nn.BatchNorm1d(num_filters_1)
        self.relu1 = nn.ReLU()
        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)
        self.drop1 = nn.Dropout(dropout_rate)

        self.conv2 = nn.Conv1d(num_filters_1, num_filters_2, kernel_size=3, padding='same')
        self.bn2 = nn.BatchNorm1d(num_filters_2)
        self.relu2 = nn.ReLU()
        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)
        self.drop2 = nn.Dropout(dropout_rate)

        self.conv3 = nn.Conv1d(num_filters_2, num_filters_3, kernel_size=3, padding='same')
        self.bn3 = nn.BatchNorm1d(num_filters_3)
        self.relu3 = nn.ReLU()
        self.pool3 = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)
        self.drop3 = nn.Dropout(dropout_rate)
        
        current_seq_len = SEQUENCE_LENGTH_AE // 8
        self.flattened_size = num_filters_3 * current_seq_len
        self.shape_before_flatten = (num_filters_3, current_seq_len)

        self.flatten = nn.Flatten()
        self.fc_encoded = nn.Linear(self.flattened_size, encoding_dim)
        self.relu_encoded = nn.ReLU()

    def forward(self, x):
        x = self.drop1(self.pool1(self.relu1(self.bn1(self.conv1(x)))))
        x = self.drop2(self.pool2(self.relu2(self.bn2(self.conv2(x)))))
        x = self.drop3(self.pool3(self.relu3(self.bn3(self.conv3(x)))))
        x = self.flatten(x)
        encoded = self.relu_encoded(self.fc_encoded(x))
        return encoded

class Decoder(nn.Module):
    def __init__(self, encoding_dim, shape_before_flatten, dropout_rate, num_filters_1, num_filters_2, num_filters_3):
        super(Decoder, self).__init__()
        self.shape_before_flatten = shape_before_flatten
        decoder_dense_target_size = np.prod(shape_before_flatten)

        self.fc_decode = nn.Linear(encoding_dim, decoder_dense_target_size)
        self.relu_decode_fc = nn.ReLU()

        self.conv_t1 = nn.Conv1d(shape_before_flatten[0], num_filters_3, kernel_size=3, padding='same')
        self.bn_t1 = nn.BatchNorm1d(num_filters_3)
        self.relu_t1 = nn.ReLU()
        self.upsample1 = nn.Upsample(scale_factor=2, mode='nearest')
        self.drop_t1 = nn.Dropout(dropout_rate)

        self.conv_t2 = nn.Conv1d(num_filters_3, num_filters_2, kernel_size=3, padding='same')
        self.bn_t2 = nn.BatchNorm1d(num_filters_2)
        self.relu_t2 = nn.ReLU()
        self.upsample2 = nn.Upsample(scale_factor=2, mode='nearest')
        self.drop_t2 = nn.Dropout(dropout_rate)

        self.conv_t3 = nn.Conv1d(num_filters_2, num_filters_1, kernel_size=3, padding='same')
        self.bn_t3 = nn.BatchNorm1d(num_filters_1)
        self.relu_t3 = nn.ReLU()
        self.upsample3 = nn.Upsample(scale_factor=2, mode='nearest')

        self.conv_out = nn.Conv1d(num_filters_1, INPUT_CHANNELS_AE, kernel_size=3, padding='same')

    def forward(self, x):
        x = self.relu_decode_fc(self.fc_decode(x))
        x = x.view(-1, self.shape_before_flatten[0], self.shape_before_flatten[1])
        x = self.drop_t1(self.upsample1(self.relu_t1(self.bn_t1(self.conv_t1(x)))))
        x = self.drop_t2(self.upsample2(self.relu_t2(self.bn_t2(self.conv_t2(x)))))
        x = self.upsample3(self.relu_t3(self.bn_t3(self.conv_t3(x))))
        decoded = self.conv_out(x)
        return decoded

class Autoencoder(nn.Module):
    def __init__(self, encoding_dim, dropout_rate, num_filters_1, num_filters_2, num_filters_3):
        super(Autoencoder, self).__init__()
        self.encoder = Encoder(encoding_dim, dropout_rate, num_filters_1, num_filters_2, num_filters_3)
        self.decoder = Decoder(encoding_dim, self.encoder.shape_before_flatten, dropout_rate,
                               num_filters_1, num_filters_2, num_filters_3)
    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded

def objective_ae(trial):
    encoding_dim = trial.suggest_categorical('encoding_dim', [16, 24, 32, 48, 64])
    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5, step=0.05) # finer steps
    num_filters_1 = trial.suggest_categorical('num_filters_1', [16, 32, 48])
    num_filters_2 = trial.suggest_categorical('num_filters_2', [32, 48, 64, 96])
    num_filters_3 = trial.suggest_categorical('num_filters_3', [64, 96, 128, 160])
    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)
    weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-2, log=True)

    model = Autoencoder(encoding_dim, dropout_rate, num_filters_1, num_filters_2, num_filters_3).to(device)
    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)
    criterion = nn.MSELoss()

    N_EPOCHS_PER_TRIAL = 30 # Adjust based on available time/resources
    AE_PATIENCE_PER_TRIAL = 7
    best_val_loss_trial = float('inf')
    patience_counter_trial = 0

    print(f"\nOptuna Trial {trial.number}: enc_dim={encoding_dim}, drop={dropout_rate:.2f}, "
          f"filters=({num_filters_1},{num_filters_2},{num_filters_3}), lr={lr:.1e}, wd={weight_decay:.1e}")

    for epoch in range(N_EPOCHS_PER_TRIAL):
        model.train()
        train_loss_epoch = 0.0
        for batch_X, _ in train_loader_ae:
            batch_X = batch_X.to(device)
            optimizer.zero_grad()
            outputs = model(batch_X)
            loss = criterion(outputs, batch_X)
            loss.backward()
            optimizer.step()
            train_loss_epoch += loss.item() * batch_X.size(0)
        train_loss_epoch /= len(train_loader_ae.dataset)

        model.eval()
        val_loss_epoch = 0.0
        with torch.no_grad():
            for batch_X_val, _ in val_loader_ae:
                batch_X_val = batch_X_val.to(device)
                outputs_val = model(batch_X_val)
                loss_val = criterion(outputs_val, batch_X_val)
                val_loss_epoch += loss_val.item() * batch_X_val.size(0)
        val_loss_epoch /= len(val_loader_ae.dataset)

        if (epoch + 1) % 10 == 0 or epoch == N_EPOCHS_PER_TRIAL -1:
             print(f"  Epoch {epoch+1}/{N_EPOCHS_PER_TRIAL} - Train Loss: {train_loss_epoch:.6f} - Val Loss: {val_loss_epoch:.6f}")

        if val_loss_epoch < best_val_loss_trial:
            best_val_loss_trial = val_loss_epoch
            patience_counter_trial = 0
        else:
            patience_counter_trial += 1
            if patience_counter_trial >= AE_PATIENCE_PER_TRIAL:
                print(f"  Early stopping trial {trial.number} at epoch {epoch+1}")
                break
        
        trial.report(val_loss_epoch, epoch)
        if trial.should_prune():
            raise optuna.exceptions.TrialPruned()
    return best_val_loss_trial

N_TRIALS_OPTUNA = 50 # Number of Optuna trials. Adjust as needed.
study_ae = optuna.create_study(direction='minimize', pruner=optuna.pruners.MedianPruner())
study_ae.optimize(objective_ae, n_trials=N_TRIALS_OPTUNA)

print("\n--- Optuna Study Finished ---")
best_trial_ae = study_ae.best_trial
print(f"Best AE trial value (min val_loss): {best_trial_ae.value}")
print("Best AE Params: ")
for key, value in best_trial_ae.params.items(): print(f"    {key}: {value}")

best_params_ae = best_trial_ae.params
autoencoder_best = Autoencoder(
    encoding_dim=best_params_ae['encoding_dim'],
    dropout_rate=best_params_ae['dropout_rate'],
    num_filters_1=best_params_ae['num_filters_1'],
    num_filters_2=best_params_ae['num_filters_2'],
    num_filters_3=best_params_ae['num_filters_3']
).to(device)

optimizer_ae_best = optim.Adam(autoencoder_best.parameters(), lr=best_params_ae['lr'], weight_decay=best_params_ae['weight_decay'])
criterion_ae_best = nn.MSELoss()
scheduler_ae_best = optim.lr_scheduler.ReduceLROnPlateau(optimizer_ae_best, mode='min', factor=0.5, patience=10, min_lr=1e-7)

print("\n--- Training Best Autoencoder Model Found by Optuna ---")
AE_TRAIN_EPOCHS_FINAL = 150 # Final training epochs
AE_PATIENCE_FINAL = 20
best_val_loss_final_ae = float('inf')
patience_counter_final_ae = 0
history_ae_loss_final, history_ae_val_loss_final = [], []

for epoch in range(AE_TRAIN_EPOCHS_FINAL):
    epoch_start_time = time.time()
    autoencoder_best.train()
    train_loss_ae = 0.0
    # ... (training loop identical to previous final training) ...
    for batch_X, _ in train_loader_ae: # Target is batch_X itself
        batch_X = batch_X.to(device)
        optimizer_ae_best.zero_grad()
        outputs = autoencoder_best(batch_X)
        loss = criterion_ae_best(outputs, batch_X)
        loss.backward()
        optimizer_ae_best.step()
        train_loss_ae += loss.item() * batch_X.size(0)
    train_loss_ae /= len(train_loader_ae.dataset)
    history_ae_loss_final.append(train_loss_ae)

    autoencoder_best.eval()
    val_loss_ae = 0.0
    with torch.no_grad():
        for batch_X_val, _ in val_loader_ae:
            batch_X_val = batch_X_val.to(device)
            outputs_val = autoencoder_best(batch_X_val)
            loss_val_ae = criterion_ae_best(outputs_val, batch_X_val) # Use distinct var name
            val_loss_ae += loss_val_ae.item() * batch_X_val.size(0)
    val_loss_ae /= len(val_loader_ae.dataset)
    history_ae_val_loss_final.append(val_loss_ae)
    epoch_duration = time.time() - epoch_start_time
    
    print(f"Final AE Epoch {epoch+1}/{AE_TRAIN_EPOCHS_FINAL} - {epoch_duration:.2f}s - loss: {train_loss_ae:.6f} - val_loss: {val_loss_ae:.6f} - LR: {optimizer_ae_best.param_groups[0]['lr']:.1e}")
    scheduler_ae_best.step(val_loss_ae)

    if val_loss_ae < best_val_loss_final_ae:
        best_val_loss_final_ae = val_loss_ae
        torch.save(autoencoder_best.state_dict(), 'best_optuna_autoencoder.pth')
        torch.save(autoencoder_best.encoder.state_dict(), 'best_optuna_encoder.pth')
        patience_counter_final_ae = 0
    else:
        patience_counter_final_ae += 1
        if patience_counter_final_ae >= AE_PATIENCE_FINAL:
            print(f"Final AE Training: Early stopping at epoch {epoch+1}")
            autoencoder_best.load_state_dict(torch.load('best_optuna_autoencoder.pth'))
            break
print("Best Autoencoder training (found by Optuna) finished.")

plt.figure(figsize=(10, 4))
plt.plot(history_ae_loss_final, label='AE Train Loss (Best Optuna)')
plt.plot(history_ae_val_loss_final, label='AE Val Loss (Best Optuna)')
plt.title('Autoencoder Training Loss (Best Optuna Model)'); plt.xlabel('Epoch'); plt.ylabel('Loss (MSE)'); plt.legend(); plt.grid(True)
plt.show(block=False)

best_encoder_params_ae = best_params_ae # Store for classifier

# --- Part 4: Generative Adversarial Network (GAN) Model ---
print("\n--- Part 4: Generative Adversarial Network (GAN) ---")
class GeneratorGAN(nn.Module):
    def __init__(self, latent_dim, output_shape_gan):
        super(GeneratorGAN, self).__init__()
        self.output_shape_gan = output_shape_gan
        self.fc1 = nn.Linear(latent_dim, 128)
        self.relu1 = nn.ReLU()
        self.fc2 = nn.Linear(128, 256)
        self.relu2 = nn.ReLU()
        required_dense_size = np.prod(output_shape_gan)
        self.fc3 = nn.Linear(256, required_dense_size)
        self.tanh = nn.Tanh()
    def forward(self, x):
        x = self.relu1(self.fc1(x))
        x = self.relu2(self.fc2(x))
        x = self.tanh(self.fc3(x))
        return x.view(-1, *self.output_shape_gan)

class DiscriminatorGAN(nn.Module):
    def __init__(self, input_shape_gan):
        super(DiscriminatorGAN, self).__init__()
        self.conv1 = nn.Conv1d(input_shape_gan[0], 64, kernel_size=3, stride=2, padding=1)
        self.lrelu1 = nn.LeakyReLU(0.2)
        self.drop1 = nn.Dropout(0.25)
        self.conv2 = nn.Conv1d(64, 128, kernel_size=3, stride=2, padding=1)
        self.lrelu2 = nn.LeakyReLU(0.2)
        self.drop2 = nn.Dropout(0.25)
        self.global_pool = nn.AdaptiveMaxPool1d(1)
        self.flatten = nn.Flatten()
        self.fc = nn.Linear(128, 1)
        self.sigmoid = nn.Sigmoid()
    def forward(self, x):
        x = self.drop1(self.lrelu1(self.conv1(x)))
        x = self.drop2(self.lrelu2(self.conv2(x)))
        x = self.global_pool(x)
        x = self.flatten(x)
        x = self.sigmoid(self.fc(x))
        return x

generator_gan = GeneratorGAN(LATENT_DIM_GAN, (1, SEQUENCE_LENGTH)).to(device)
discriminator_gan = DiscriminatorGAN((1, SEQUENCE_LENGTH)).to(device)
opt_discriminator_gan = optim.Adam(discriminator_gan.parameters(), lr=0.0002, betas=(0.5, 0.999))
opt_generator_gan = optim.Adam(generator_gan.parameters(), lr=0.0002, betas=(0.5, 0.999))
criterion_gan = nn.BCELoss()

def train_gan_loop_pt(gen, disc, data_loader_gan, epochs, latent_dim_gan, opt_g, opt_d, criterion):
    # ... (GAN training loop - identical to previous full code) ...
    if len(data_loader_gan.dataset) == 0 or len(data_loader_gan) == 0:
        print("Not enough data for GAN training. Skipping.")
        return [], [], []
    d_losses, g_losses, d_accs = [], [], []
    print("\nStarting GAN training (PyTorch)...")
    for epoch in range(epochs):
        epoch_start_time = time.time()
        d_loss_epoch, g_loss_epoch, d_acc_epoch_val = 0,0,0
        num_batches_processed = 0
        for i, (real_signals_batch,) in enumerate(data_loader_gan):
            current_batch_size = real_signals_batch.size(0)
            if current_batch_size == 0: continue
            real_signals_batch = real_signals_batch.to(device)
            real_labels = torch.ones(current_batch_size, 1, device=device) * 0.9
            fake_labels = torch.zeros(current_batch_size, 1, device=device)

            opt_d.zero_grad()
            outputs_real = disc(real_signals_batch)
            d_loss_real = criterion(outputs_real, real_labels)
            noise = torch.randn(current_batch_size, latent_dim_gan, device=device)
            with torch.no_grad(): fake_signals = gen(noise).detach()
            outputs_fake = disc(fake_signals)
            d_loss_fake = criterion(outputs_fake, fake_labels)
            d_loss = (d_loss_real + d_loss_fake) / 2
            d_loss.backward()
            opt_d.step()
            d_loss_epoch += d_loss.item()
            d_acc_epoch_val += ((outputs_real > 0.5).float().sum().item() + (outputs_fake < 0.5).float().sum().item()) / (2 * current_batch_size)

            opt_g.zero_grad()
            noise = torch.randn(current_batch_size, latent_dim_gan, device=device)
            fake_signals_for_g = gen(noise)
            outputs_g = disc(fake_signals_for_g)
            misleading_labels = torch.ones(current_batch_size, 1, device=device)
            g_loss = criterion(outputs_g, misleading_labels)
            g_loss.backward()
            opt_g.step()
            g_loss_epoch += g_loss.item()
            num_batches_processed +=1
        
        if num_batches_processed == 0: continue
        avg_d_loss = d_loss_epoch / num_batches_processed
        avg_d_acc = d_acc_epoch_val / num_batches_processed
        avg_g_loss = g_loss_epoch / num_batches_processed
        d_losses.append(avg_d_loss); g_losses.append(avg_g_loss); d_accs.append(avg_d_acc)
        epoch_duration = time.time() - epoch_start_time

        if epoch % (epochs // 10 if epochs >=10 else 1) == 0 or epoch == epochs - 1:
            print(f"GAN Epoch {epoch+1}/{epochs} - {epoch_duration:.2f}s: D_loss={avg_d_loss:.4f}, D_acc={avg_d_acc:.4f}, G_loss={avg_g_loss:.4f}")
            # (Plotting GAN samples removed for brevity in this combined script, but can be added back)
    print("GAN training (PyTorch) finished.")
    return d_losses, g_losses, d_accs

d_losses_hist, g_losses_hist, d_accs_hist = [], [], []
if X_train_tensor.shape[0] >= GAN_BATCH_SIZE :
    d_losses_hist, g_losses_hist, d_accs_hist = train_gan_loop_pt(
        generator_gan, discriminator_gan, gan_loader,
        GAN_TRAIN_EPOCHS, LATENT_DIM_GAN,
        opt_generator_gan, opt_discriminator_gan, criterion_gan
    )
    if d_losses_hist:
        plt.figure(figsize=(12, 5)); plt.plot(d_losses_hist, label='D Loss'); plt.plot(g_losses_hist, label='G Loss')
        plt.title('GAN Losses'); plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend(); plt.grid(True); plt.show(block=False)
        plt.figure(figsize=(12, 5)); plt.plot(d_accs_hist, label='D Acc', color='green')
        plt.title('D Accuracy'); plt.xlabel('Epoch'); plt.ylabel('Acc'); plt.legend(); plt.grid(True); plt.show(block=False)
else:
    print("Skipping GAN training: not enough training data for a batch.")


# --- Part 5: Classifier Model Definition, Compilation, and Training ---
print("\n--- Part 5: Classifier Model ---")
L2_REG_CLF = 1e-4 # Can also be optimized by Optuna if desired

print("\nLoading best encoder for classifier...")
encoder_for_clf = Encoder( # Use parameters from best_encoder_params_ae
    encoding_dim=best_encoder_params_ae['encoding_dim'],
    dropout_rate=best_encoder_params_ae['dropout_rate'],
    num_filters_1=best_encoder_params_ae['num_filters_1'],
    num_filters_2=best_encoder_params_ae['num_filters_2'],
    num_filters_3=best_encoder_params_ae['num_filters_3']
).to(device)
try:
    encoder_for_clf.load_state_dict(torch.load('best_optuna_encoder.pth', map_location=device))
    print("Successfully loaded weights for best encoder into classifier's encoder.")
except FileNotFoundError: print("WARNING: 'best_optuna_encoder.pth' not found for classifier.")
except Exception as e: print(f"WARNING: Error loading 'best_optuna_encoder.pth': {e}")

class SignalClassifier(nn.Module):
    def __init__(self, encoder_features_model, num_classes_clf, latent_dim_ae_clf):
        super(SignalClassifier, self).__init__()
        self.encoder = encoder_features_model
        for param in self.encoder.parameters(): param.requires_grad = False
        
        self.fc1 = nn.Linear(latent_dim_ae_clf, 256) # Use the actual latent_dim from AE
        self.relu1 = nn.ReLU(); self.bn1 = nn.BatchNorm1d(256); self.drop1 = nn.Dropout(0.5)
        self.fc2 = nn.Linear(256, 128)
        self.relu2 = nn.ReLU(); self.bn2 = nn.BatchNorm1d(128); self.drop2 = nn.Dropout(0.4)
        self.fc3 = nn.Linear(128, 64)
        self.relu3 = nn.ReLU(); self.bn3 = nn.BatchNorm1d(64); self.drop3 = nn.Dropout(0.3)
        self.output_fc = nn.Linear(64, num_classes_clf)
    def forward(self, x):
        with torch.no_grad(): features = self.encoder(x)
        x = self.drop1(self.bn1(self.relu1(self.fc1(features))))
        x = self.drop2(self.bn2(self.relu2(self.fc2(x))))
        x = self.drop3(self.bn3(self.relu3(self.fc3(x))))
        return self.output_fc(x)

num_unique_classes = len(np.unique(y_sequences))
class_weights_computed = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)
class_weights_tensor = torch.tensor(class_weights_computed, dtype=torch.float32).to(device)

classifier = SignalClassifier(encoder_for_clf, num_classes_clf=num_unique_classes, latent_dim_ae_clf=best_encoder_params_ae['encoding_dim']).to(device)
optimizer_clf = optim.Adam(filter(lambda p: p.requires_grad, classifier.parameters()), lr=0.001, weight_decay=L2_REG_CLF)
criterion_clf = nn.CrossEntropyLoss(weight=class_weights_tensor)
scheduler_clf = optim.lr_scheduler.ReduceLROnPlateau(optimizer_clf, mode='min', factor=0.5, patience=7, min_lr=1e-7)

print("\nStarting Classifier training...")
# ... (Classifier training loop - identical to previous full code) ...
history_clf_acc, history_clf_val_acc, history_clf_loss, history_clf_val_loss = [], [], [], []
best_val_acc_clf = 0.0
patience_counter_clf = 0
CLF_PATIENCE = 15
for epoch in range(CLASSIFIER_TRAIN_EPOCHS):
    epoch_start_time = time.time()
    classifier.train()
    train_loss_clf, train_correct_clf, train_total_clf = 0.0, 0, 0
    for batch_X, batch_y in train_loader_clf:
        batch_X, batch_y = batch_X.to(device), batch_y.to(device)
        optimizer_clf.zero_grad()
        outputs = classifier(batch_X)
        loss = criterion_clf(outputs, batch_y)
        loss.backward(); optimizer_clf.step()
        train_loss_clf += loss.item() * batch_X.size(0)
        _, predicted = torch.max(outputs.data, 1)
        train_total_clf += batch_y.size(0)
        train_correct_clf += (predicted == batch_y).sum().item()
    train_loss_clf /= len(train_loader_clf.dataset); train_acc_clf = train_correct_clf / train_total_clf
    history_clf_loss.append(train_loss_clf); history_clf_acc.append(train_acc_clf)

    classifier.eval()
    val_loss_clf, val_correct_clf, val_total_clf = 0.0, 0, 0
    with torch.no_grad():
        for batch_X_val, batch_y_val in val_loader_clf:
            batch_X_val, batch_y_val = batch_X_val.to(device), batch_y_val.to(device)
            outputs_val = classifier(batch_X_val)
            loss_val = criterion_clf(outputs_val, batch_y_val) # Use distinct var
            val_loss_clf += loss_val.item() * batch_X_val.size(0)
            _, predicted_val = torch.max(outputs_val.data, 1)
            val_total_clf += batch_y_val.size(0)
            val_correct_clf += (predicted_val == batch_y_val).sum().item()
    val_loss_clf /= len(val_loader_clf.dataset); val_acc_clf = val_correct_clf / val_total_clf
    history_clf_val_loss.append(val_loss_clf); history_clf_val_acc.append(val_acc_clf)
    epoch_duration = time.time() - epoch_start_time
    print(f"CLF Epoch {epoch+1}/{CLASSIFIER_TRAIN_EPOCHS} - {epoch_duration:.2f}s - loss: {train_loss_clf:.4f} - acc: {train_acc_clf:.4f} - val_loss: {val_loss_clf:.4f} - val_acc: {val_acc_clf:.4f} - LR: {optimizer_clf.param_groups[0]['lr']:.1e}")
    scheduler_clf.step(val_loss_clf)
    if val_acc_clf > best_val_acc_clf:
        best_val_acc_clf = val_acc_clf
        torch.save(classifier.state_dict(), 'best_classifier.pth')
        patience_counter_clf = 0
    else:
        patience_counter_clf += 1
        if patience_counter_clf >= CLF_PATIENCE:
            print(f"Classifier Early stopping at epoch {epoch+1}")
            classifier.load_state_dict(torch.load('best_classifier.pth'))
            break
print("Classifier training finished.")
# Plotting classifier history (removed for brevity, can be added back)

# --- Part 6: Model Evaluation and Synthetic Data Generation ---
print("\n--- Part 6: Model Evaluation and Synthetic Data Generation ---")
def evaluate_classifier_model_pt(clf_model, test_dl, target_names):
    # ... (Evaluation function - identical to previous full code) ...
    print("\nEvaluating classifier performance on the test set (PyTorch)...")
    clf_model.eval()
    all_preds, all_true = [], []
    with torch.no_grad():
        for batch_X, batch_y in test_dl:
            batch_X, batch_y = batch_X.to(device), batch_y.to(device)
            outputs = clf_model(batch_X)
            _, predicted_classes = torch.max(outputs, 1)
            all_preds.extend(predicted_classes.cpu().numpy())
            all_true.extend(batch_y.cpu().numpy())
    print("\nClassification Report (PyTorch):")
    print(classification_report(all_true, all_preds, target_names=target_names, zero_division=0))
    # Plotting confusion matrix (removed for brevity, can be added back)

target_names_report = ['quiet', 'vehicle', 'human']
evaluate_classifier_model_pt(classifier, test_loader_clf, target_names_report)

def generate_and_plot_synthetic_signals_pt(gen_model, latent_dim_val, num_signals=3):
    # ... (Signal generation - identical to previous full code) ...
    if not d_losses_hist: # Check if GAN was trained
        print("GAN was not trained or training failed. Skipping synthetic signal generation.")
        return None
    print(f"\nGenerating {num_signals} synthetic signals using the GAN (PyTorch)...")
    gen_model.eval()
    with torch.no_grad():
        noise_samples = torch.randn(num_signals, latent_dim_val, device=device)
        synthetic_signals_gen = gen_model(noise_samples).cpu().numpy()
    # Plotting signals (removed for brevity, can be added back)
    return synthetic_signals_gen

synthetic_signals_output = generate_and_plot_synthetic_signals_pt(generator_gan, LATENT_DIM_GAN)

print("\n--- PyTorch Machine Learning Pipeline Completed ---")
# Ensure all plots are shown at the end if plt.show(block=False) was used
plt.show()
