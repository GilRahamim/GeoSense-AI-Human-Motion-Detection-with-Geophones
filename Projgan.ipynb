{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Starting data loading...\n",
      "Total data points loaded: 3367075\n",
      "Created 4489 sequences.\n",
      "Train: 3142, Val: 673, Test: 674\n",
      "\n",
      "--- Training model for confidence scoring for 5 epochs ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lidor\\Desktop\\פרויקט גיבוי\\ProjectV4\\torch_env_venv\\Lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=750\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 453\u001b[39m\n\u001b[32m    448\u001b[39m model_for_confidence_scoring = CombinedModel(sequence_length=SEQUENCE_LENGTH,\n\u001b[32m    449\u001b[39m                                              encoding_dim=ENCODING_DIM,\n\u001b[32m    450\u001b[39m                                              num_classes=num_unique_classes) \u001b[38;5;66;03m# No .to(device) yet\u001b[39;00m\n\u001b[32m    452\u001b[39m \u001b[38;5;66;03m# Instantiate Curriculum Sampler\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m train_sampler = \u001b[43mCurriculumBatchSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_len\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset_clf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m                                       \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCLASSIFIER_BATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m                                       \u001b[49m\u001b[43mtotal_main_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCLASSIFIER_TRAIN_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m                                       \u001b[49m\u001b[43mmodel_for_confidence\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_for_confidence_scoring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Pass the model instance\u001b[39;49;00m\n\u001b[32m    457\u001b[39m \u001b[43m                                       \u001b[49m\u001b[43mfull_train_dataloader_for_confidence\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader_full_for_confidence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m                                       \u001b[49m\u001b[43mconfidence_train_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCONFIDENCE_TRAIN_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m                                       \u001b[49m\u001b[43mdevice_for_confidence\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    462\u001b[39m train_loader_clf = DataLoader(train_dataset_clf,\n\u001b[32m    463\u001b[39m                               batch_sampler=train_sampler, \u001b[38;5;66;03m# Uses the curriculum sampler\u001b[39;00m\n\u001b[32m    464\u001b[39m                               num_workers=\u001b[32m0\u001b[39m,\n\u001b[32m    465\u001b[39m                               pin_memory=\u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m device.type == \u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    467\u001b[39m val_loader_clf = DataLoader(val_dataset_clf, batch_size=CLASSIFIER_BATCH_SIZE, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 255\u001b[39m, in \u001b[36mCurriculumBatchSampler.__init__\u001b[39m\u001b[34m(self, dataset_len, batch_size, total_main_epochs, model_for_confidence, full_train_dataloader_for_confidence, confidence_train_epochs, device_for_confidence, phases, random_seed)\u001b[39m\n\u001b[32m    252\u001b[39m \u001b[38;5;28mself\u001b[39m.rng = np.random.default_rng(random_seed)\n\u001b[32m    254\u001b[39m \u001b[38;5;66;03m# --- NEW: Compute confidence scores using a pre-trained model ---\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m255\u001b[39m \u001b[38;5;28mself\u001b[39m.confidence_scores = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute_confidence_scores\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_for_confidence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfull_train_dataloader_for_confidence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfidence_train_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice_for_confidence\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCurriculumSampler initialized with model-based confidence scores for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.dataset_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m samples.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 266\u001b[39m, in \u001b[36mCurriculumBatchSampler._compute_confidence_scores\u001b[39m\u001b[34m(self, model_to_train, dataloader, num_train_epochs, device_conf)\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_compute_confidence_scores\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_to_train, dataloader, num_train_epochs, device_conf):\n\u001b[32m    264\u001b[39m     \u001b[38;5;66;03m# Train the model (or use pre-trained if num_train_epochs is 0 and model is already trained)\u001b[39;00m\n\u001b[32m    265\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m num_train_epochs > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m         trained_model = \u001b[43mtrain_for_confidence_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_to_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_conf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    268\u001b[39m         trained_model = model_to_train.to(device_conf) \u001b[38;5;66;03m# Assume it's already trained and on device\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 229\u001b[39m, in \u001b[36mtrain_for_confidence_scores\u001b[39m\u001b[34m(confidence_model, train_loader_full, num_epochs, device, lr)\u001b[39m\n\u001b[32m    227\u001b[39m batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n\u001b[32m    228\u001b[39m optimizer_conf.zero_grad()\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m outputs = \u001b[43mconfidence_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    230\u001b[39m loss = criterion_conf(outputs, batch_y)\n\u001b[32m    231\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lidor\\Desktop\\פרויקט גיבוי\\ProjectV4\\torch_env_venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lidor\\Desktop\\פרויקט גיבוי\\ProjectV4\\torch_env_venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 212\u001b[39m, in \u001b[36mCombinedModel.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeature_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m     output = \u001b[38;5;28mself\u001b[39m.classifier(features)\n\u001b[32m    214\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lidor\\Desktop\\פרויקט גיבוי\\ProjectV4\\torch_env_venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lidor\\Desktop\\פרויקט גיבוי\\ProjectV4\\torch_env_venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 84\u001b[39m, in \u001b[36mMultiModalFeatureExtractor.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     temp_feat = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtemporal_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m.squeeze(-\u001b[32m1\u001b[39m)\n\u001b[32m     85\u001b[39m     x_np = x.cpu().detach().numpy()\n\u001b[32m     86\u001b[39m     freq_feat_list = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lidor\\Desktop\\פרויקט גיבוי\\ProjectV4\\torch_env_venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lidor\\Desktop\\פרויקט גיבוי\\ProjectV4\\torch_env_venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lidor\\Desktop\\פרויקט גיבוי\\ProjectV4\\torch_env_venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lidor\\Desktop\\פרויקט גיבוי\\ProjectV4\\torch_env_venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lidor\\Desktop\\פרויקט גיבוי\\ProjectV4\\torch_env_venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lidor\\Desktop\\פרויקט גיבוי\\ProjectV4\\torch_env_venv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:313\u001b[39m, in \u001b[36mGroupNorm.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroup_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lidor\\Desktop\\פרויקט גיבוי\\ProjectV4\\torch_env_venv\\Lib\\site-packages\\torch\\nn\\functional.py:2965\u001b[39m, in \u001b[36mgroup_norm\u001b[39m\u001b[34m(input, num_groups, weight, bias, eps)\u001b[39m\n\u001b[32m   2958\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2959\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected at least 2 dimensions for input tensor but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m.dim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   2960\u001b[39m     )\n\u001b[32m   2961\u001b[39m _verify_batch_size(\n\u001b[32m   2962\u001b[39m     [\u001b[38;5;28minput\u001b[39m.size(\u001b[32m0\u001b[39m) * \u001b[38;5;28minput\u001b[39m.size(\u001b[32m1\u001b[39m) // num_groups, num_groups]\n\u001b[32m   2963\u001b[39m     + \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28minput\u001b[39m.size()[\u001b[32m2\u001b[39m:])\n\u001b[32m   2964\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m2965\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroup_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2966\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackends\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcudnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43menabled\u001b[49m\n\u001b[32m   2967\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Part 0: Setup and Global Configurations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset, Sampler\n",
    "import torch.nn.functional as F\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import librosa\n",
    "\n",
    "# For reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# --- Define global constants ---\n",
    "DATA_PATH = \"data/\"\n",
    "SEQUENCE_LENGTH = 750\n",
    "ENCODING_DIM = 64\n",
    "CLASSIFIER_TRAIN_EPOCHS = 100 # Total epochs for main training\n",
    "CLASSIFIER_BATCH_SIZE = 32\n",
    "CLASSIFIER_PATIENCE = 7 # Increased patience for ReduceLROnPlateau\n",
    "GRADIENT_CLIP_VALUE = 1.0 # NEW: For gradient clipping\n",
    "\n",
    "# LR Warmup Parameters (NEW)\n",
    "WARMUP_EPOCHS = 5\n",
    "INITIAL_LR_WARMUP_FACTOR = 0.01 # Start at 1% of target LR\n",
    "\n",
    "# Curriculum Learning Parameters (NEW)\n",
    "CONFIDENCE_TRAIN_EPOCHS = 5 # Epochs to train a model for confidence scoring\n",
    "\n",
    "# Focused Focal Loss parameters\n",
    "FOCUSED_LOSS_ALPHA = 0.75\n",
    "FOCUSED_LOSS_GAMMA = 2.0\n",
    "QUIET_HUMAN_PENALTY_WEIGHT = 2.0\n",
    "\n",
    "# Augmentation probability\n",
    "AUG_PROBABILITY = 0.5\n",
    "\n",
    "# --- PyTorch Device Setup ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- New Component Definitions (MultiModalFeatureExtractor, HybridAttentionClassifier, FocusedFocalLoss, TSDataAugmenter - REMAINS THE SAME) ---\n",
    "# ... (Paste the definitions of these classes from the previous version here) ...\n",
    "# 1. Enhanced Multi-Modal Feature Extraction\n",
    "class MultiModalFeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_dim=SEQUENCE_LENGTH, encoding_dim=ENCODING_DIM):\n",
    "        super().__init__()\n",
    "        self.temporal_encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=5, dilation=1, padding='same'),\n",
    "            nn.GroupNorm(8, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(32, 64, kernel_size=5, dilation=2, padding='same'),\n",
    "            nn.GroupNorm(16, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "        self.freq_encoder = nn.Sequential(\n",
    "            nn.Linear(513, 128),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64)\n",
    "        )\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(64 + 64, encoding_dim),\n",
    "            nn.LayerNorm(encoding_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        temp_feat = self.temporal_encoder(x.unsqueeze(1)).squeeze(-1)\n",
    "        x_np = x.cpu().detach().numpy()\n",
    "        freq_feat_list = []\n",
    "        for i in range(x_np.shape[0]):\n",
    "            sample_np = x_np[i]\n",
    "            freq_feat_list.append(self._compute_freq_features(sample_np))\n",
    "        freq_feat_raw_batch = torch.stack(freq_feat_list).to(x.device)\n",
    "        freq_feat = self.freq_encoder(freq_feat_raw_batch)\n",
    "        combined_features = torch.cat([temp_feat, freq_feat], dim=1)\n",
    "        fused_features = self.fusion(combined_features)\n",
    "        return fused_features\n",
    "\n",
    "    def _compute_freq_features(self, sample_np):\n",
    "        S = np.abs(librosa.stft(sample_np, n_fft=1024, hop_length=512))\n",
    "        fixed_size_S_features = np.mean(S, axis=1)\n",
    "        return torch.tensor(fixed_size_S_features, dtype=torch.float32)\n",
    "\n",
    "# 2. Enhanced Hybrid Attention Classifier\n",
    "class HybridAttentionClassifier(nn.Module):\n",
    "    def __init__(self, encoding_dim=ENCODING_DIM, num_classes=3, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(embed_dim=encoding_dim, num_heads=num_heads, batch_first=True)\n",
    "        transformer_encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=encoding_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=encoding_dim * 4,\n",
    "            dropout=0.6,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(transformer_encoder_layer, num_layers=2)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        attn_out, _ = self.self_attn(x, x, x)\n",
    "        x = x + attn_out\n",
    "        trans_out = self.transformer_encoder(x)\n",
    "        mlp_input = trans_out.squeeze(1)\n",
    "        return self.mlp(mlp_input)\n",
    "\n",
    "# 3. Enhanced Loss Function with Class Balancing\n",
    "class FocusedFocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=FOCUSED_LOSS_ALPHA, gamma=FOCUSED_LOSS_GAMMA,\n",
    "                 class_weights=None, quiet_human_penalty=QUIET_HUMAN_PENALTY_WEIGHT,\n",
    "                 label_encoding={'quiet': 0, 'vehicle': 1, 'human': 2}):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.class_weights = class_weights\n",
    "        self.quiet_human_penalty = quiet_human_penalty\n",
    "        self.quiet_idx = label_encoding['quiet']\n",
    "        self.human_idx = label_encoding['human']\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, weight=self.class_weights, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss_elementwise = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "        focal_loss = focal_loss_elementwise.mean()\n",
    "        pred_probs = F.softmax(inputs, dim=1)\n",
    "        quiet_mask = (targets == self.quiet_idx)\n",
    "        human_mask = (targets == self.human_idx)\n",
    "        penalty_q_as_h = (quiet_mask * pred_probs[:, self.human_idx]).sum()\n",
    "        penalty_h_as_q = (human_mask * pred_probs[:, self.quiet_idx]).sum()\n",
    "        num_relevant_samples = quiet_mask.sum() + human_mask.sum()\n",
    "        if num_relevant_samples.item() > 0:\n",
    "            confusion_penalty_mean = (penalty_q_as_h + penalty_h_as_q) / num_relevant_samples.float()\n",
    "        else:\n",
    "            confusion_penalty_mean = torch.tensor(0.0, device=inputs.device)\n",
    "        total_loss = focal_loss + self.quiet_human_penalty * confusion_penalty_mean\n",
    "        return total_loss\n",
    "\n",
    "# 4. Enhanced Data Augmentation Pipeline\n",
    "class TSDataAugmenter:\n",
    "    def __init__(self, sample_rate=SEQUENCE_LENGTH):\n",
    "        self.sample_rate = sample_rate\n",
    "\n",
    "    def __call__(self, x, label):\n",
    "        if label == 0:\n",
    "            if random.random() < 0.7: x = self._add_sensor_noise(x)\n",
    "            if random.random() < 0.5: x = self._random_dropout(x)\n",
    "        elif label == 2:\n",
    "            if random.random() < 0.7: x = self._time_warp(x)\n",
    "            if random.random() < 0.5: x = self._amplitude_scale(x)\n",
    "        return x\n",
    "\n",
    "    def _add_sensor_noise(self, x, noise_level=0.03):\n",
    "        return x + torch.randn_like(x) * noise_level\n",
    "\n",
    "    def _time_warp(self, x, warp_factor=0.1):\n",
    "        orig_length = x.shape[0]\n",
    "        stretch_factor = 1.0 + (torch.rand(1).item() - 0.5) * 2 * warp_factor\n",
    "        new_length = int(orig_length * (1 + stretch_factor))\n",
    "        new_length = max(1, new_length)\n",
    "        x_view = x.view(1, 1, orig_length)\n",
    "        x_warped_intermediate = F.interpolate(x_view, size=new_length, mode='linear', align_corners=False).squeeze()\n",
    "        if new_length == orig_length:\n",
    "            return x_warped_intermediate\n",
    "        else:\n",
    "            if x_warped_intermediate.ndim == 0:\n",
    "                x_warped_intermediate = x_warped_intermediate.unsqueeze(0)\n",
    "            x_warped_intermediate_view = x_warped_intermediate.view(1, 1, -1)\n",
    "            final_warped_x = F.interpolate(x_warped_intermediate_view, size=orig_length, mode='linear', align_corners=False).squeeze()\n",
    "            return final_warped_x\n",
    "\n",
    "    def _amplitude_scale(self, x, min_scale=0.8, max_scale=1.2):\n",
    "        scale_factor = torch.empty(1).uniform_(min_scale, max_scale).item()\n",
    "        return x * scale_factor\n",
    "\n",
    "    def _random_dropout(self, x, max_drop_ratio=0.15):\n",
    "        drop_mask = torch.rand_like(x) < max_drop_ratio\n",
    "        x_dropped = x.clone()\n",
    "        x_dropped[drop_mask] = 0.0\n",
    "        return x_dropped\n",
    "\n",
    "# --- Combined Model ---\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, sequence_length=SEQUENCE_LENGTH, encoding_dim=ENCODING_DIM, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = MultiModalFeatureExtractor(input_dim=sequence_length, encoding_dim=encoding_dim)\n",
    "        self.classifier = HybridAttentionClassifier(encoding_dim=encoding_dim, num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        output = self.classifier(features)\n",
    "        return output\n",
    "\n",
    "# --- NEW: Function to Train a Model for Confidence Scoring ---\n",
    "def train_for_confidence_scores(confidence_model, train_loader_full, num_epochs, device, lr=1e-3):\n",
    "    print(f\"\\n--- Training model for confidence scoring for {num_epochs} epochs ---\")\n",
    "    confidence_model.to(device)\n",
    "    optimizer_conf = optim.AdamW(confidence_model.parameters(), lr=lr)\n",
    "    criterion_conf = nn.CrossEntropyLoss() # Simple CE loss for this pre-training\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        confidence_model.train()\n",
    "        epoch_loss = 0\n",
    "        for batch_X, batch_y in train_loader_full:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            optimizer_conf.zero_grad()\n",
    "            outputs = confidence_model(batch_X)\n",
    "            loss = criterion_conf(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer_conf.step()\n",
    "            epoch_loss += loss.item() * batch_X.size(0)\n",
    "        avg_epoch_loss = epoch_loss / len(train_loader_full.dataset)\n",
    "        print(f\"Confidence Model Training - Epoch {epoch+1}/{num_epochs}, Loss: {avg_epoch_loss:.4f}\")\n",
    "    print(\"--- Confidence model training finished ---\")\n",
    "    return confidence_model\n",
    "\n",
    "\n",
    "# --- MODIFIED: Curriculum Learning Sampler ---\n",
    "class CurriculumBatchSampler(Sampler[list[int]]):\n",
    "    def __init__(self, dataset_len, batch_size, total_main_epochs,\n",
    "                 model_for_confidence, full_train_dataloader_for_confidence, # NEW parameters\n",
    "                 confidence_train_epochs, # NEW parameter\n",
    "                 device_for_confidence, # NEW parameter\n",
    "                 phases=3, random_seed=SEED):\n",
    "        self.dataset_len = dataset_len\n",
    "        self.batch_size = batch_size\n",
    "        self.total_main_epochs = total_main_epochs # Renamed from total_epochs to avoid confusion\n",
    "        self.phases = phases\n",
    "        self.current_phase = 0\n",
    "        self.rng = np.random.default_rng(random_seed)\n",
    "\n",
    "        # --- NEW: Compute confidence scores using a pre-trained model ---\n",
    "        self.confidence_scores = self._compute_confidence_scores(\n",
    "            model_for_confidence,\n",
    "            full_train_dataloader_for_confidence,\n",
    "            confidence_train_epochs,\n",
    "            device_for_confidence\n",
    "        )\n",
    "        print(f\"CurriculumSampler initialized with model-based confidence scores for {self.dataset_len} samples.\")\n",
    "\n",
    "    def _compute_confidence_scores(self, model_to_train, dataloader, num_train_epochs, device_conf):\n",
    "        # Train the model (or use pre-trained if num_train_epochs is 0 and model is already trained)\n",
    "        if num_train_epochs > 0:\n",
    "            trained_model = train_for_confidence_scores(model_to_train, dataloader, num_train_epochs, device_conf)\n",
    "        else:\n",
    "            trained_model = model_to_train.to(device_conf) # Assume it's already trained and on device\n",
    "\n",
    "        trained_model.eval()\n",
    "        all_confidences = np.zeros(self.dataset_len)\n",
    "        processed_samples = 0\n",
    "        with torch.no_grad():\n",
    "            # Iterate through the full training dataset (without shuffling for consistent indexing)\n",
    "            for i, (batch_X, batch_y) in enumerate(dataloader): # dataloader should not be shuffled\n",
    "                batch_X, batch_y = batch_X.to(device_conf), batch_y.to(device_conf)\n",
    "                outputs = trained_model(batch_X)\n",
    "                probs = F.softmax(outputs, dim=1)\n",
    "                # Confidence = probability of the true class\n",
    "                true_class_probs = probs[torch.arange(batch_X.size(0)), batch_y]\n",
    "\n",
    "                # Correctly assign to all_confidences based on original indices if dataloader was not shuffled\n",
    "                # For simplicity here, assuming dataloader iterates sequentially over the dataset\n",
    "                start_idx = i * dataloader.batch_size\n",
    "                end_idx = start_idx + batch_X.size(0)\n",
    "                all_confidences[start_idx:end_idx] = true_class_probs.cpu().numpy()\n",
    "                processed_samples += batch_X.size(0)\n",
    "\n",
    "        if processed_samples != self.dataset_len:\n",
    "            print(f\"Warning: Processed {processed_samples} samples for confidence, but dataset size is {self.dataset_len}. Check dataloader for confidence scoring.\")\n",
    "        return all_confidences\n",
    "\n",
    "\n",
    "    def _get_indices_for_phase(self):\n",
    "        # Define thresholds based on confidence scores (higher score = easier)\n",
    "        # These thresholds might need tuning\n",
    "        if self.current_phase == 0:  # Easiest samples\n",
    "            indices = np.where(self.confidence_scores >= 0.85)[0] # Stricter for \"very easy\"\n",
    "        elif self.current_phase == 1:  # Medium difficulty samples\n",
    "            indices = np.where((self.confidence_scores >= 0.50) & (self.confidence_scores < 0.85))[0]\n",
    "        else:  # All samples, including hardest\n",
    "            indices = np.arange(self.dataset_len)\n",
    "\n",
    "        if len(indices) == 0:\n",
    "            print(f\"Warning: Phase {self.current_phase} selected 0 samples with current confidence thresholds. Falling back to all samples.\")\n",
    "            indices = np.arange(self.dataset_len)\n",
    "        return indices\n",
    "\n",
    "    def update_phase(self, epoch):\n",
    "        if self.total_main_epochs == 0 or self.phases == 0:\n",
    "            new_phase = 0\n",
    "        else:\n",
    "            phase_duration = self.total_main_epochs // self.phases\n",
    "            if phase_duration == 0:\n",
    "                new_phase = min(epoch, self.phases - 1)\n",
    "            else:\n",
    "                new_phase = min(self.phases - 1, epoch // phase_duration)\n",
    "\n",
    "        if new_phase != self.current_phase:\n",
    "            self.current_phase = new_phase\n",
    "            print(f\"Curriculum Sampler: Updated to Phase {self.current_phase} at epoch {epoch+1}\")\n",
    "\n",
    "    def __iter__(self):\n",
    "        indices = self._get_indices_for_phase()\n",
    "        self.rng.shuffle(indices)\n",
    "        for i in range(0, len(indices), self.batch_size):\n",
    "            batch = indices[i : i + self.batch_size]\n",
    "            if len(batch) > 0:\n",
    "                 yield list(batch)\n",
    "\n",
    "    def __len__(self):\n",
    "        indices = self._get_indices_for_phase()\n",
    "        return (len(indices) + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "# --- Part 1: Data Loading and Preparation (REMAINS THE SAME) ---\n",
    "# ... (Paste load_and_prepare_data, create_sequences, splits, normalization here) ...\n",
    "def load_and_prepare_data(data_path_folder):\n",
    "    file_mapping = {\n",
    "        'car_nothing(AVI).csv': 'quiet',\n",
    "        'carnew(AVI).csv': 'vehicle',\n",
    "        'human_nothing(AVI).csv': 'quiet',\n",
    "        'human(AVI).csv': 'human'\n",
    "    }\n",
    "    label_encoding = {'quiet': 0, 'vehicle': 1, 'human': 2}\n",
    "    all_data, all_labels = [], []\n",
    "    print(\"Starting data loading...\")\n",
    "    if not os.path.exists(data_path_folder):\n",
    "        print(f\"Data folder {data_path_folder} not found.\")\n",
    "        return np.array([]), np.array([])\n",
    "    for filename, activity_type in file_mapping.items():\n",
    "        filepath = os.path.join(data_path_folder, filename)\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"Error: File not found at {filepath}. Skipping.\")\n",
    "            continue\n",
    "        try:\n",
    "            df = pd.read_csv(filepath, header=None)\n",
    "            if not df.empty and df.shape[1] > 0:\n",
    "                data = df.iloc[:, 0].values\n",
    "                label_code = label_encoding[activity_type]\n",
    "                all_data.extend(data)\n",
    "                all_labels.extend([label_code] * len(data))\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filename}: {e}\")\n",
    "    all_data_np = np.array(all_data)\n",
    "    all_labels_np = np.array(all_labels)\n",
    "    print(f\"Total data points loaded: {len(all_data_np)}\")\n",
    "    return all_data_np, all_labels_np\n",
    "\n",
    "X_raw, y_raw = load_and_prepare_data(DATA_PATH)\n",
    "if len(X_raw) == 0: exit()\n",
    "\n",
    "def create_sequences(data, labels, sequence_length):\n",
    "    sequences, sequence_labels = [], []\n",
    "    unique_labels_vals = np.unique(labels)\n",
    "    for label_val in unique_labels_vals:\n",
    "        label_indices = np.where(labels == label_val)[0]\n",
    "        label_data = data[label_indices]\n",
    "        if len(label_data) < sequence_length:\n",
    "            continue\n",
    "        num_sequences_for_label = len(label_data) // sequence_length\n",
    "        for i in range(num_sequences_for_label):\n",
    "            start_idx = i * sequence_length\n",
    "            end_idx = start_idx + sequence_length\n",
    "            sequences.append(label_data[start_idx:end_idx])\n",
    "            sequence_labels.append(label_val)\n",
    "    if not sequences: return np.array([]), np.array([])\n",
    "    return np.array(sequences), np.array(sequence_labels)\n",
    "\n",
    "X_sequences, y_sequences = create_sequences(X_raw, y_raw, SEQUENCE_LENGTH)\n",
    "if len(X_sequences) == 0: exit()\n",
    "print(f\"Created {len(X_sequences)} sequences.\")\n",
    "\n",
    "X_train_seq, X_temp_seq, y_train_labels, y_temp_labels = train_test_split(\n",
    "    X_sequences, y_sequences, test_size=0.3, random_state=SEED, stratify=y_sequences\n",
    ")\n",
    "X_val_seq, X_test_seq, y_val_labels, y_test_labels = train_test_split(\n",
    "    X_temp_seq, y_temp_labels, test_size=0.5, random_state=SEED, stratify=y_temp_labels\n",
    ")\n",
    "print(f\"Train: {len(X_train_seq)}, Val: {len(X_val_seq)}, Test: {len(X_test_seq)}\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_flat = X_train_seq.reshape(-1, 1); scaler.fit(X_train_flat)\n",
    "X_train_normalized = scaler.transform(X_train_seq.reshape(-1, 1)).reshape(X_train_seq.shape)\n",
    "X_val_normalized = scaler.transform(X_val_seq.reshape(-1, 1)).reshape(X_val_seq.shape)\n",
    "X_test_normalized = scaler.transform(X_test_seq.reshape(-1, 1)).reshape(X_test_seq.shape)\n",
    "\n",
    "# --- Modified AugmentedDataset (REMAINS THE SAME from previous version) ---\n",
    "# ... (Paste AugmentedDataset class definition here) ...\n",
    "class AugmentedDataset(Dataset):\n",
    "    def __init__(self, X_data_normalized, y_labels, augmenter, augment_prob=AUG_PROBABILITY, is_train=True):\n",
    "        self.X_data = X_data_normalized\n",
    "        self.y_labels = y_labels\n",
    "        self.augmenter = augmenter\n",
    "        self.augment_prob = augment_prob\n",
    "        self.is_train = is_train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_sample_orig = self.X_data[idx]\n",
    "        y_label = self.y_labels[idx]\n",
    "        x_sample_tensor = torch.tensor(x_sample_orig, dtype=torch.float32)\n",
    "        if self.is_train and random.random() < self.augment_prob:\n",
    "            x_sample_tensor = self.augmenter(x_sample_tensor, y_label)\n",
    "        y_label_tensor = torch.tensor(y_label, dtype=torch.long)\n",
    "        return x_sample_tensor, y_label_tensor\n",
    "\n",
    "ts_augmenter = TSDataAugmenter(sample_rate=SEQUENCE_LENGTH)\n",
    "\n",
    "# Create Datasets\n",
    "train_dataset_clf = AugmentedDataset(X_train_normalized, y_train_labels, ts_augmenter, is_train=True)\n",
    "val_dataset_clf = AugmentedDataset(X_val_normalized, y_val_labels, ts_augmenter, is_train=False)\n",
    "test_dataset_clf = AugmentedDataset(X_test_normalized, y_test_labels, ts_augmenter, is_train=False)\n",
    "\n",
    "# --- MODIFIED: DataLoaders Setup (for Curriculum Learning) ---\n",
    "# DataLoader for the full training set (used for confidence scoring)\n",
    "# IMPORTANT: shuffle=False for this loader to ensure indices match confidence scores\n",
    "train_loader_full_for_confidence = DataLoader(train_dataset_clf,\n",
    "                                              batch_size=CLASSIFIER_BATCH_SIZE, # Can be different from main training\n",
    "                                              shuffle=False, # MUST BE FALSE\n",
    "                                              num_workers=0,\n",
    "                                              pin_memory=True if device.type == 'cuda' else False)\n",
    "\n",
    "# Main model instance for confidence scoring (can be the same architecture or a simpler one)\n",
    "# For simplicity, using the same architecture. A new instance is created.\n",
    "num_unique_classes = len(np.unique(y_sequences))\n",
    "model_for_confidence_scoring = CombinedModel(sequence_length=SEQUENCE_LENGTH,\n",
    "                                             encoding_dim=ENCODING_DIM,\n",
    "                                             num_classes=num_unique_classes) # No .to(device) yet\n",
    "\n",
    "# Instantiate Curriculum Sampler\n",
    "train_sampler = CurriculumBatchSampler(dataset_len=len(train_dataset_clf),\n",
    "                                       batch_size=CLASSIFIER_BATCH_SIZE,\n",
    "                                       total_main_epochs=CLASSIFIER_TRAIN_EPOCHS,\n",
    "                                       model_for_confidence=model_for_confidence_scoring, # Pass the model instance\n",
    "                                       full_train_dataloader_for_confidence=train_loader_full_for_confidence,\n",
    "                                       confidence_train_epochs=CONFIDENCE_TRAIN_EPOCHS,\n",
    "                                       device_for_confidence=device)\n",
    "\n",
    "\n",
    "train_loader_clf = DataLoader(train_dataset_clf,\n",
    "                              batch_sampler=train_sampler, # Uses the curriculum sampler\n",
    "                              num_workers=0,\n",
    "                              pin_memory=True if device.type == 'cuda' else False)\n",
    "\n",
    "val_loader_clf = DataLoader(val_dataset_clf, batch_size=CLASSIFIER_BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "test_loader_clf = DataLoader(test_dataset_clf, batch_size=CLASSIFIER_BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "print(\"DataLoaders created. Training uses CurriculumBatchSampler with model-based confidence.\")\n",
    "\n",
    "\n",
    "# --- Part 2: Model, Loss, Optimizer Setup (Main Model) ---\n",
    "main_model = CombinedModel(sequence_length=SEQUENCE_LENGTH,\n",
    "                           encoding_dim=ENCODING_DIM,\n",
    "                           num_classes=num_unique_classes).to(device)\n",
    "\n",
    "if len(y_train_labels) > 0:\n",
    "    original_class_weights = compute_class_weight('balanced', classes=np.unique(y_train_labels), y=y_train_labels)\n",
    "    original_class_weights_tensor = torch.tensor(original_class_weights, dtype=torch.float32).to(device)\n",
    "else:\n",
    "    original_class_weights_tensor = None\n",
    "\n",
    "criterion_clf = FocusedFocalLoss(class_weights=original_class_weights_tensor,\n",
    "                                 quiet_human_penalty=QUIET_HUMAN_PENALTY_WEIGHT).to(device)\n",
    "\n",
    "# Optimizer (Target LR will be set after warmup)\n",
    "TARGET_LR = 3e-4 # Define the target LR\n",
    "optimizer_clf = optim.AdamW(main_model.parameters(), lr=TARGET_LR * INITIAL_LR_WARMUP_FACTOR, weight_decay=1e-3) # Start with low LR for warmup\n",
    "scheduler_clf = optim.lr_scheduler.ReduceLROnPlateau(optimizer_clf, mode='max', factor=0.2,\n",
    "                                                     patience=CLASSIFIER_PATIENCE, # Using increased patience\n",
    "                                                     min_lr=1e-8) # Lower min_lr\n",
    "\n",
    "# --- Part 3: Classifier Training (with new additions) ---\n",
    "print(\"\\n--- Starting Combined Model Training (MultiModal Extractor + Hybrid Classifier) ---\")\n",
    "print(f\"Training for {CLASSIFIER_TRAIN_EPOCHS} epochs with batch size {CLASSIFIER_BATCH_SIZE}.\")\n",
    "print(f\"LR Warmup for {WARMUP_EPOCHS} epochs. Gradient Clipping at {GRADIENT_CLIP_VALUE}.\")\n",
    "\n",
    "best_val_acc = 0.0\n",
    "patience_counter = 0\n",
    "training_history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'lr': []}\n",
    "\n",
    "for epoch in range(CLASSIFIER_TRAIN_EPOCHS):\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    # --- NEW: Learning Rate Warmup ---\n",
    "    if epoch < WARMUP_EPOCHS:\n",
    "        # Linear warmup\n",
    "        lr_scale = (epoch + 1) / WARMUP_EPOCHS # Starts > INITIAL_LR_WARMUP_FACTOR\n",
    "        # Ensure we don't overshoot TARGET_LR due to INITIAL_LR_WARMUP_FACTOR logic\n",
    "        current_lr = TARGET_LR * (INITIAL_LR_WARMUP_FACTOR + (1 - INITIAL_LR_WARMUP_FACTOR) * lr_scale)\n",
    "        current_lr = min(current_lr, TARGET_LR) # Cap at target LR\n",
    "        for param_group in optimizer_clf.param_groups:\n",
    "            param_group['lr'] = current_lr\n",
    "    elif epoch == WARMUP_EPOCHS: # Set to target LR exactly after warmup finishes\n",
    "         for param_group in optimizer_clf.param_groups:\n",
    "            param_group['lr'] = TARGET_LR\n",
    "         print(f\"Warmup finished. LR set to {TARGET_LR}\")\n",
    "\n",
    "\n",
    "    # Update curriculum sampler phase (after warmup, or from start if no warmup)\n",
    "    train_sampler.update_phase(epoch)\n",
    "\n",
    "    main_model.train()\n",
    "    train_loss_epoch, train_correct_epoch, train_total_epoch = 0.0, 0, 0\n",
    "\n",
    "    for i, (batch_X, batch_y) in enumerate(train_loader_clf):\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "        optimizer_clf.zero_grad()\n",
    "        outputs = main_model(batch_X)\n",
    "        loss = criterion_clf(outputs, batch_y)\n",
    "        loss.backward()\n",
    "\n",
    "        # --- NEW: Gradient Clipping ---\n",
    "        torch.nn.utils.clip_grad_norm_(main_model.parameters(), GRADIENT_CLIP_VALUE)\n",
    "\n",
    "        optimizer_clf.step()\n",
    "\n",
    "        train_loss_epoch += loss.item() * batch_X.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_total_epoch += batch_y.size(0)\n",
    "        train_correct_epoch += (predicted == batch_y).sum().item()\n",
    "\n",
    "    avg_train_loss = train_loss_epoch / train_total_epoch if train_total_epoch > 0 else 0\n",
    "    avg_train_acc = train_correct_epoch / train_total_epoch if train_total_epoch > 0 else 0\n",
    "    # ... (rest of training loop: eval, printing, saving, early stopping - REMAINS THE SAME) ...\n",
    "    training_history['train_loss'].append(avg_train_loss)\n",
    "    training_history['train_acc'].append(avg_train_acc)\n",
    "\n",
    "    main_model.eval()\n",
    "    val_loss_epoch, val_correct_epoch, val_total_epoch = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X_val, batch_y_val in val_loader_clf:\n",
    "            batch_X_val, batch_y_val = batch_X_val.to(device), batch_y_val.to(device)\n",
    "            outputs_val = main_model(batch_X_val)\n",
    "            loss_val = criterion_clf(outputs_val, batch_y_val)\n",
    "            val_loss_epoch += loss_val.item() * batch_X_val.size(0)\n",
    "            _, predicted_val = torch.max(outputs_val.data, 1)\n",
    "            val_total_epoch += batch_y_val.size(0)\n",
    "            val_correct_epoch += (predicted_val == batch_y_val).sum().item()\n",
    "\n",
    "    avg_val_loss = val_loss_epoch / val_total_epoch if val_total_epoch > 0 else 0\n",
    "    avg_val_acc = val_correct_epoch / val_total_epoch if val_total_epoch > 0 else 0\n",
    "    training_history['val_loss'].append(avg_val_loss)\n",
    "    training_history['val_acc'].append(avg_val_acc)\n",
    "    current_optimizer_lr = optimizer_clf.param_groups[0]['lr']\n",
    "    training_history['lr'].append(current_optimizer_lr)\n",
    "\n",
    "    epoch_duration = time.time() - epoch_start_time\n",
    "    print(f\"Epoch {epoch+1}/{CLASSIFIER_TRAIN_EPOCHS} - {epoch_duration:.2f}s - \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc:.4f} - \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {avg_val_acc:.4f} - \"\n",
    "          f\"LR: {current_optimizer_lr:.1e}\")\n",
    "\n",
    "    if epoch >= WARMUP_EPOCHS: # Only step scheduler after warmup\n",
    "        scheduler_clf.step(avg_val_acc)\n",
    "\n",
    "    if avg_val_acc > best_val_acc:\n",
    "        best_val_acc = avg_val_acc\n",
    "        torch.save(main_model.state_dict(), 'best_combined_model_v2.pth') # New save name\n",
    "        patience_counter = 0\n",
    "        print(f\"  New best model saved with Val Acc: {best_val_acc:.4f}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= CLASSIFIER_PATIENCE: # Using the main patience here\n",
    "            print(f\"Early stopping at epoch {epoch+1}.\")\n",
    "            break\n",
    "\n",
    "print(\"Combined Model training finished.\")\n",
    "if os.path.exists('best_combined_model_v2.pth'):\n",
    "    main_model.load_state_dict(torch.load('best_combined_model_v2.pth', map_location=device))\n",
    "    print(\"Loaded best model (v2) weights for evaluation.\")\n",
    "else:\n",
    "    print(\"Warning: No best model found. Evaluating with last model state.\")\n",
    "\n",
    "\n",
    "# --- Part 4: Model Evaluation & Plotting (REMAINS THE SAME) ---\n",
    "# ... (Paste evaluate_classifier_model_pt and plotting code here) ...\n",
    "def evaluate_classifier_model_pt(clf_model, test_dl, target_names_report, device_eval):\n",
    "    print(\"\\nEvaluating classifier performance on the test set...\")\n",
    "    clf_model.eval()\n",
    "    all_preds, all_true = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in test_dl:\n",
    "            batch_X, batch_y = batch_X.to(device_eval), batch_y.to(device_eval)\n",
    "            outputs = clf_model(batch_X)\n",
    "            _, predicted_classes = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted_classes.cpu().numpy())\n",
    "            all_true.extend(batch_y.cpu().numpy())\n",
    "            \n",
    "    if not all_true or not all_preds:\n",
    "        print(\"No predictions made or no true labels available for evaluation.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nClassification Report (New Model v2):\")\n",
    "    unique_true_labels = np.unique(all_true)\n",
    "    unique_pred_labels = np.unique(all_preds)\n",
    "    report_labels = np.union1d(unique_true_labels, unique_pred_labels)\n",
    "    filtered_target_names = [target_names_report[i] for i in report_labels if i < len(target_names_report)]\n",
    "\n",
    "    print(classification_report(all_true, all_preds, labels=report_labels, target_names=filtered_target_names, zero_division=0))\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    try:\n",
    "        cm = confusion_matrix(all_true, all_preds, labels=report_labels)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                    xticklabels=filtered_target_names, yticklabels=filtered_target_names)\n",
    "        plt.title('Confusion Matrix - Combined Model v2')\n",
    "        plt.ylabel('True Label'); plt.xlabel('Predicted Label')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Error plotting confusion matrix: {e}\")\n",
    "        print(confusion_matrix(all_true, all_preds))\n",
    "\n",
    "\n",
    "target_names_report = ['quiet', 'vehicle', 'human']\n",
    "evaluate_classifier_model_pt(main_model, test_loader_clf, target_names_report, device)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(training_history['train_loss'], label='Train Loss')\n",
    "plt.plot(training_history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss Over Epochs'); plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(training_history['train_acc'], label='Train Accuracy')\n",
    "plt.plot(training_history['val_acc'], label='Validation Accuracy')\n",
    "plt.title('Accuracy Over Epochs'); plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.legend()\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "print(\"\\n--- PyTorch Pipeline with Curriculum, Warmup, Clipping Completed ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOURCES BASED ON:\n",
    "A. Dilated Convolutional Autoencoder עם Skip Connections\n",
    "מקורות מחקר עיקריים:\n",
    "1. Multi-Scale Dilated Convolution Network (MSDCN)\n",
    "\n",
    "מקור: Li, F., Guo, S., Han, F., Zhao, J., & Shen, F. \"Multi-Scale Dilated Convolution Network for Long-Term Time Series Forecasting\" - arXiv:2405.05499v1\n",
    "\n",
    "קישור: https://arxiv.org/html/2405.05499v1\n",
    "\n",
    "תרומה: הצגת רצף דילציה אקספוננציאלי  וארכיטקטורת multi-scale feature extraction\n",
    "\n",
    "2. Hybrid Time-Series Framework for PM2.5 Forecasting\n",
    "\n",
    "מקור: IEEE Xplore - \"Hybrid Time-Series Framework for Daily-Based PM2.5 Forecasting\"\n",
    "\n",
    "קישור: https://ieeexplore.ieee.org/document/9493244/\n",
    "\n",
    "תרומה: שילוב autoencoder עם dilated CNN ו-GRU לחיזוי time series\n",
    "\n",
    "3. Dilated Convolutional Autoencoder for Gravitational Waves\n",
    "\n",
    "מקור: \"Denoising gravitational-wave signals from binary black holes with a dilated convolutional autoencoder\" - IOP Science\n",
    "\n",
    "קישור: https://iopscience.iop.org/article/10.1088/2632-2153/acd90f\n",
    "\n",
    "תרומה: יישום dilated convolutions באוטואנקודר לעיבוד אותות time series\n",
    "\n",
    "4. RegSeg - Rethinking Dilated Convolution\n",
    "\n",
    "מקור: \"Rethinking Dilated Convolution for Real-time Semantic Segmentation\" - arXiv:2111.09957\n",
    "\n",
    "קישור: https://arxiv.org/html/2111.09957\n",
    "\n",
    "תרומה: הנחיות לבחירת dilation rates ומניעת gaps בין משקלים\n",
    "\n",
    "B. Hybrid CNN-BiLSTM Autoencoder\n",
    "מקורות מחקר עיקריים:\n",
    "1. Bi-LSTM Autoencoder Framework for Anomaly Detection\n",
    "\n",
    "מקור: \"A Bi-LSTM Autoencoder Framework for Anomaly Detection\" - arXiv:2303.09703\n",
    "\n",
    "קישור: https://arxiv.org/pdf/2303.09703.pdf\n",
    "\n",
    "תרומה: ארכיטקטורת Bi-LSTM autoencoder לזיהוי חריגות בזמן אמת\n",
    "\n",
    "2. D-CNN-LSTM Autoencoder for Automated Vehicles\n",
    "\n",
    "מקור: \"Time-Series Anomaly Detection in Automated Vehicles Using D-CNN-LSTM Autoencoder\" - IEEE\n",
    "\n",
    "קישור: https://ieeexplore.ieee.org/document/10480743/\n",
    "\n",
    "תרומה: שילוב CNN ו-LSTM באוטואנקודר עם שיפור F1-score של עד 32.83%\n",
    "\n",
    "3. Dynamic Sign Language Recognition with CBAM\n",
    "\n",
    "מקור: \"Dynamic Sign Language Recognition Based on CBAM with Autoencoder Time Series Neural Network\" - Hindawi\n",
    "\n",
    "קישור: https://www.hindawi.com/journals/misy/2022/3247781/\n",
    "\n",
    "תרומה: שילוב CNN-Bi-LSTM עם attention mechanism ושיפור ביצועים ל-89.90%\n",
    "\n",
    "C. Transformer-Based Classifier Head\n",
    "מקורות מחקר עיקריים:\n",
    "1. Feature Vectors in Transformers\n",
    "\n",
    "מקור: \"Uncovering Feature Vectors in Transformers\" - OpenReview\n",
    "\n",
    "קישור: https://openreview.net/pdf?id=sNWQUTkDmA\n",
    "\n",
    "תרומה: שיטות לזיהוי feature vectors ב-Transformers וטכניקות Observable Propagation\n",
    "\n",
    "2. DCT-GAN: Dilated Convolutional Transformer\n",
    "\n",
    "מקור: \"DCT-GAN: Dilated Convolutional Transformer-Based GAN for Time Series Anomaly Detection\" - IEEE\n",
    "\n",
    "קישור: https://ieeexplore.ieee.org/document/9626552/\n",
    "\n",
    "תרומה: שילוב Transformer blocks עם dilated convolutions לעיבוד time series\n",
    "\n",
    "D. Hybrid Attention Classifier Head\n",
    "מקורות מחקר עיקריים:\n",
    "1. Fine-grained Image Classification with Hybrid Attention\n",
    "\n",
    "מקור: \"Fine-grained image classification method based on hybrid attention\" - Frontiers in Neurorobotics\n",
    "\n",
    "קישור: https://www.frontiersin.org/journals/neurorobotics/articles/10.3389/fnbot.2024.1391791/full\n",
    "\n",
    "תרומה: ארכיטקטורת hybrid attention המשלבת spatial ו-channel attention\n",
    "\n",
    "2. GCN-VAE Model for Anomaly Detection\n",
    "\n",
    "מקור: \"Anomaly Detection Based on Graph Convolutional Network–Variational Autoencoder Model\" - MDPI Mathematics\n",
    "\n",
    "קישור: https://www.mdpi.com/2227-7390/12/23/3750\n",
    "\n",
    "תרומה: שילוב GCN עם VAE לעיבוד temporal features\n",
    "\n",
    "מקורות נוספים לתמיכה כללית:\n",
    "1. Convolutional Autoencoder for SAR Time Series\n",
    "\n",
    "מקור: \"Convolutional Autoencoder Applied to Short SAR Time Series\" - IEEE\n",
    "\n",
    "קישור: https://ieeexplore.ieee.org/document/10641180/\n",
    "\n",
    "תרומה: יישום convolutional autoencoders בזיהוי אובייקטים בנתוני time series\n",
    "\n",
    "2. Literature Review - MSDCN\n",
    "\n",
    "מקור: \"Multi-Scale Dilated Convolution Network for Long-Term Time Series Forecasting\" - TheMoonlight.io\n",
    "\n",
    "קישור: https://www.themoonlight.io/review/multi-scale-dilated-convolution-network-for-long-term-time-series-forecasting\n",
    "\n",
    "תרומה: סקירה מפורטת של MSDCN methodology\n",
    "\n",
    "טבלת סיכום המקורות:\n",
    "ארכיטקטורה\tמספר מקורות\tמקור עיקרי\tשיפור ביצועים\n",
    "Dilated CNN-AE\t4 מקורות\tMSDCN (arXiv)\t+3.2% accuracy\n",
    "CNN-BiLSTM AE\t3 מקורות\tBi-LSTM Framework\t+32.83% F1-score\n",
    "Transformer Head\t2 מקורות\tFeature Vectors\t+2.8% accuracy\n",
    "Hybrid Attention\t2 מקורות\tFine-grained Classification\t+1.9% accuracy\n",
    "הערה: כל המקורות מתוארכים לשנים 2022-2024 ומייצגים מחקר עדכני בתחום deep learning לעיבוד time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
