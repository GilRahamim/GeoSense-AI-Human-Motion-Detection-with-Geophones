{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5e815f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 PyTorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import signal\n",
    "from scipy.fft import fft, fftfreq\n",
    "import librosa\n",
    "import librosa.display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"🔧 PyTorch device: {device}\")\n",
    "\n",
    "# הגדרת matplotlib לעברית\n",
    "plt.rcParams['font.family'] = ['Arial Unicode MS', 'Tahoma', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# פונקציה מתוקנת לטעינת נתונים\n",
    "def load_geophone_data():\n",
    "    \"\"\"טעינת כל קבצי הנתונים\"\"\"\n",
    "    \n",
    "    file_mapping = {\n",
    "        'man.csv': 'human',\n",
    "        'car.csv': 'vehicle', \n",
    "        'car2.csv': 'vehicle',\n",
    "        'nothing.csv': 'quiet'\n",
    "    }\n",
    "    \n",
    "    data_dict = {}\n",
    "    labels_dict = {}\n",
    "    \n",
    "    print(\"🔄 טעינת קבצי נתונים...\")\n",
    "    \n",
    "    for filename, label in file_mapping.items():\n",
    "        try:\n",
    "            # קריאת הקובץ\n",
    "            df = pd.read_csv(filename, header=None)\n",
    "            print(f\"✅ נטען {filename}: {df.shape[0]} שורות, {df.shape[1]} עמודות\")\n",
    "            \n",
    "            # המרה למערך numpy\n",
    "            data_dict[filename] = df.values\n",
    "            labels_dict[filename] = label\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"❌ לא נמצא קובץ: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ שגיאה בטעינת {filename}: {e}\")\n",
    "    \n",
    "    return data_dict, labels_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaa0b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_raw_data(data_dict, labels_dict, window_size_seconds=2, sample_rate=1000):\n",
    "    \"\"\"הכנת נתונים גולמיים עם חלונות זמן\"\"\"\n",
    "    \n",
    "    window_size = window_size_seconds * sample_rate  # 2000 דגימות\n",
    "    \n",
    "    raw_windows = []\n",
    "    labels = []\n",
    "    \n",
    "    # חישוב מספר כולל של חלונות לtqdm\n",
    "    total_windows = 0\n",
    "    for filename, signal_data in data_dict.items():\n",
    "        total_windows += (signal_data.shape[0] - window_size) // (window_size // 2)\n",
    "    \n",
    "    print(f\"🔄 יצירת {total_windows} חלונות של {window_size_seconds} שניות...\")\n",
    "    \n",
    "    with tqdm(total=total_windows, desc=\"עיבוד חלונות גולמיים\") as pbar:\n",
    "        for filename, signal_data in data_dict.items():\n",
    "            label = labels_dict[filename]\n",
    "            \n",
    "            # חלונות עם overlap של 50%\n",
    "            step_size = window_size // 2\n",
    "            \n",
    "            for start_idx in range(0, signal_data.shape[0] - window_size + 1, step_size):\n",
    "                end_idx = start_idx + window_size\n",
    "                window = signal_data[start_idx:end_idx]\n",
    "                \n",
    "                if window.shape[0] == window_size:\n",
    "                    raw_windows.append(window)\n",
    "                    labels.append(label)\n",
    "                \n",
    "                pbar.update(1)\n",
    "                if pbar.n >= total_windows:\n",
    "                    break\n",
    "    \n",
    "    return np.array(raw_windows), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd8f3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_raw_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"מודל CNN לנתונים גולמיים (2D: זמן × חיישנים)\"\"\"\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        # Input layer\n",
    "        layers.Input(shape=input_shape),\n",
    "        \n",
    "        # הוספת dimension channel\n",
    "        layers.Reshape(input_shape + (1,)),\n",
    "        \n",
    "        # CNN layers - רואה דפוסים בזמן ובין חיישנים\n",
    "        layers.Conv2D(16, (5, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 1)),\n",
    "        layers.BatchNormalization(),\n",
    "        \n",
    "        layers.Conv2D(32, (5, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 1)),\n",
    "        layers.BatchNormalization(),\n",
    "        \n",
    "        layers.Conv2D(64, (3, 2), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 1)),\n",
    "        layers.BatchNormalization(),\n",
    "        \n",
    "        layers.Conv2D(128, (3, 2), activation='relu', padding='same'),\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        \n",
    "        # Dense layers\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # Output\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e188b3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_raw_1d_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"מודל CNN 1D שמעבד כל חיישן בנפרד ואז מאחד\"\"\"\n",
    "    \n",
    "    # Input\n",
    "    input_layer = layers.Input(shape=input_shape)  # (2000, num_sensors)\n",
    "    \n",
    "    # עיבוד כל חיישן בנפרד\n",
    "    sensor_outputs = []\n",
    "    \n",
    "    for i in range(input_shape[1]):  # עבור כל חיישן\n",
    "        # חילוץ חיישן בודד\n",
    "        sensor_data = layers.Lambda(lambda x, idx=i: x[:, :, idx:idx+1])(input_layer)\n",
    "        \n",
    "        # CNN 1D על החיישן\n",
    "        x = layers.Conv1D(32, 11, activation='relu', padding='same')(sensor_data)\n",
    "        x = layers.MaxPooling1D(2)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Conv1D(64, 7, activation='relu', padding='same')(x)\n",
    "        x = layers.MaxPooling1D(2)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Conv1D(128, 5, activation='relu', padding='same')(x)\n",
    "        x = layers.GlobalAveragePooling1D()(x)\n",
    "        \n",
    "        sensor_outputs.append(x)\n",
    "    \n",
    "    # איחוד כל החיישנים\n",
    "    if len(sensor_outputs) > 1:\n",
    "        combined = layers.Concatenate()(sensor_outputs)\n",
    "    else:\n",
    "        combined = sensor_outputs[0]\n",
    "    \n",
    "    # Dense layers\n",
    "    x = layers.Dense(256, activation='relu')(combined)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Output\n",
    "    output = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = keras.Model(inputs=input_layer, outputs=output)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd6c2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_raw_model(model_type='2d'):\n",
    "    \"\"\"אימון מודל על נתונים גולמיים\"\"\"\n",
    "    \n",
    "    print(\"🔄 שלב 1: אימון על נתונים גולמיים\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # טעינת נתונים\n",
    "    data_dict, labels_dict = load_geophone_data()\n",
    "    \n",
    "    if not data_dict:\n",
    "        print(\"❌ לא נמצאו קבצי נתונים!\")\n",
    "        return None\n",
    "    \n",
    "    # הכנת נתונים גולמיים\n",
    "    X_raw, y_raw = prepare_raw_data(data_dict, labels_dict, window_size_seconds=2)\n",
    "    \n",
    "    print(f\"✅ נוצרו {len(X_raw)} חלונות גולמיים\")\n",
    "    print(f\"📊 צורת חלון: {X_raw[0].shape}\")\n",
    "    print(f\"📈 טווח ערכים: {X_raw.min():.4f} עד {X_raw.max():.4f}\")\n",
    "    \n",
    "    # קידוד תוויות\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y_raw)\n",
    "    y_categorical = tf.keras.utils.to_categorical(y_encoded)\n",
    "    \n",
    "    print(f\"🏷️ קטגוריות: {label_encoder.classes_}\")\n",
    "    \n",
    "    # נורמליזציה\n",
    "    X_normalized = (X_raw - X_raw.mean()) / X_raw.std()\n",
    "    \n",
    "    # חלוקת נתונים\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_normalized, y_categorical, \n",
    "        test_size=0.2, random_state=42, stratify=y_encoded\n",
    "    )\n",
    "    \n",
    "    print(f\"📈 אימון: {X_train.shape[0]} דגימות\")\n",
    "    print(f\"📉 בדיקה: {X_test.shape[0]} דגימות\")\n",
    "    \n",
    "    # בניית מודל\n",
    "    print(f\"\\n🏗️ בניית מודל CNN {model_type.upper()}...\")\n",
    "    if model_type == '2d':\n",
    "        model = create_raw_cnn_model(X_train[0].shape, len(label_encoder.classes_))\n",
    "    else:\n",
    "        model = create_raw_1d_cnn_model(X_train[0].shape, len(label_encoder.classes_))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    print(\"📋 סיכום מודל נתונים גולמיים:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "    ]\n",
    "    \n",
    "    # אימון\n",
    "    print(f\"\\n🎯 אימון מודל נתונים גולמיים...\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=32,\n",
    "        epochs=50,\n",
    "        validation_split=0.2,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # הערכה\n",
    "    print(\"\\n📊 הערכת מודל נתונים גולמיים...\")\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"🎯 דיוק מודל גולמי: {test_accuracy:.4f}\")\n",
    "    \n",
    "    # תחזיות\n",
    "    y_pred = model.predict(X_test, verbose=0)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_test_classes = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    print(\"\\n📈 דוח ביצועים - מודל גולמי:\")\n",
    "    print(classification_report(\n",
    "        y_test_classes, y_pred_classes, \n",
    "        target_names=label_encoder.classes_\n",
    "    ))\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'history': history,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'label_encoder': label_encoder,\n",
    "        'predictions': (y_test_classes, y_pred_classes),\n",
    "        'type': 'raw_' + model_type\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ecf2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeophoneFeatureExtractor:\n",
    "    def __init__(self, sample_rate=1000, window_size=2048, hop_length=512):\n",
    "        self.sample_rate = sample_rate\n",
    "        self.window_size = window_size\n",
    "        self.hop_length = hop_length\n",
    "    \n",
    "    def extract_mel_spectrogram(self, signal_data, channel=0):\n",
    "        \"\"\"חילוץ מל-ספקטוגרמה\"\"\"\n",
    "        if channel >= signal_data.shape[1]:\n",
    "            channel = 0\n",
    "            \n",
    "        mel_spec = librosa.feature.melspectrogram(\n",
    "            y=signal_data[:, channel].astype(float),\n",
    "            sr=self.sample_rate,\n",
    "            n_mels=128,\n",
    "            hop_length=self.hop_length,\n",
    "            n_fft=self.window_size\n",
    "        )\n",
    "        \n",
    "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        return mel_spec_db\n",
    "    \n",
    "    def extract_fft_features(self, signal_data):\n",
    "        \"\"\"חילוץ מאפיינים באמצעות FFT\"\"\"\n",
    "        fft_features = []\n",
    "        \n",
    "        for i in range(signal_data.shape[1]):\n",
    "            fft_vals = fft(signal_data[:, i])\n",
    "            fft_magnitude = np.abs(fft_vals[:len(fft_vals)//2])\n",
    "            \n",
    "            features = [\n",
    "                np.mean(fft_magnitude),\n",
    "                np.std(fft_magnitude),\n",
    "                np.max(fft_magnitude),\n",
    "                np.sum(fft_magnitude),\n",
    "                np.median(fft_magnitude),\n",
    "                np.percentile(fft_magnitude, 75),\n",
    "                np.percentile(fft_magnitude, 25)\n",
    "            ]\n",
    "            fft_features.extend(features)\n",
    "        \n",
    "        return np.array(fft_features)\n",
    "    \n",
    "    def extract_time_domain_features(self, signal_data):\n",
    "        \"\"\"חילוץ מאפיינים בתחום הזמן\"\"\"\n",
    "        features = []\n",
    "        \n",
    "        for i in range(signal_data.shape[1]):\n",
    "            channel_data = signal_data[:, i]\n",
    "            \n",
    "            features.extend([\n",
    "                np.mean(channel_data),\n",
    "                np.std(channel_data),\n",
    "                np.var(channel_data),\n",
    "                np.max(channel_data),\n",
    "                np.min(channel_data),\n",
    "                np.ptp(channel_data),\n",
    "                np.mean(np.abs(channel_data)),\n",
    "                np.sqrt(np.mean(channel_data**2)),\n",
    "            ])\n",
    "            \n",
    "            # Zero crossing rate\n",
    "            zero_crossings = np.where(np.diff(np.signbit(channel_data)))[0]\n",
    "            zcr = len(zero_crossings) / len(channel_data)\n",
    "            features.append(zcr)\n",
    "            \n",
    "            # Spectral centroid\n",
    "            try:\n",
    "                spectral_centroid = librosa.feature.spectral_centroid(\n",
    "                    y=channel_data.astype(float), sr=self.sample_rate\n",
    "                )[0]\n",
    "                features.append(np.mean(spectral_centroid))\n",
    "            except:\n",
    "                features.append(0)\n",
    "        \n",
    "        return np.array(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d1f3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_advanced_data(data_dict, labels_dict, segment_length=2000):\n",
    "    \"\"\"הכנת נתונים עם מאפיינים מתקדמים\"\"\"\n",
    "    \n",
    "    extractor = GeophoneFeatureExtractor()\n",
    "    \n",
    "    spectrograms = []\n",
    "    fft_features = []\n",
    "    time_features = []\n",
    "    labels = []\n",
    "    \n",
    "    total_segments = sum(signal_data.shape[0] // segment_length \n",
    "                        for signal_data in data_dict.values())\n",
    "    \n",
    "    print(f\"🔄 עיבוד {total_segments} סגמנטים מתקדמים...\")\n",
    "    \n",
    "    with tqdm(total=total_segments, desc=\"עיבוד מאפיינים מתקדמים\") as pbar:\n",
    "        for filename, signal_data in data_dict.items():\n",
    "            label = labels_dict[filename]\n",
    "            num_segments = signal_data.shape[0] // segment_length\n",
    "            \n",
    "            for i in range(num_segments):\n",
    "                start_idx = i * segment_length\n",
    "                end_idx = start_idx + segment_length\n",
    "                segment = signal_data[start_idx:end_idx]\n",
    "                \n",
    "                if segment.shape[0] < segment_length:\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    mel_spec = extractor.extract_mel_spectrogram(segment, channel=0)\n",
    "                    fft_feat = extractor.extract_fft_features(segment)\n",
    "                    time_feat = extractor.extract_time_domain_features(segment)\n",
    "                    \n",
    "                    spectrograms.append(mel_spec)\n",
    "                    fft_features.append(fft_feat)\n",
    "                    time_features.append(time_feat)\n",
    "                    labels.append(label)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"שגיאה בעיבוד: {e}\")\n",
    "                \n",
    "                pbar.update(1)\n",
    "    \n",
    "    return np.array(spectrograms), np.array(fft_features), np.array(time_features), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1525529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_advanced_model(spectrogram_shape, fft_features_shape, time_features_shape, num_classes):\n",
    "    \"\"\"מודל מתקדם עם ספקטוגרמה + מאפיינים\"\"\"\n",
    "    \n",
    "    # Inputs\n",
    "    spectrogram_input = layers.Input(shape=spectrogram_shape, name='spectrogram_input')\n",
    "    fft_input = layers.Input(shape=(fft_features_shape,), name='fft_input')\n",
    "    time_input = layers.Input(shape=(time_features_shape,), name='time_input')\n",
    "    \n",
    "    # CNN לספקטוגרמה\n",
    "    x1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(spectrogram_input)\n",
    "    x1 = layers.MaxPooling2D((2, 2))(x1)\n",
    "    x1 = layers.BatchNormalization()(x1)\n",
    "    \n",
    "    x1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x1)\n",
    "    x1 = layers.MaxPooling2D((2, 2))(x1)\n",
    "    x1 = layers.BatchNormalization()(x1)\n",
    "    \n",
    "    x1 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x1)\n",
    "    x1 = layers.GlobalAveragePooling2D()(x1)\n",
    "    x1 = layers.Dense(256, activation='relu')(x1)\n",
    "    x1 = layers.Dropout(0.3)(x1)\n",
    "    \n",
    "    # Dense למאפייני FFT\n",
    "    x2 = layers.Dense(128, activation='relu')(fft_input)\n",
    "    x2 = layers.BatchNormalization()(x2)\n",
    "    x2 = layers.Dropout(0.3)(x2)\n",
    "    x2 = layers.Dense(64, activation='relu')(x2)\n",
    "    \n",
    "    # Dense למאפיינים בזמן\n",
    "    x3 = layers.Dense(128, activation='relu')(time_input)\n",
    "    x3 = layers.BatchNormalization()(x3)\n",
    "    x3 = layers.Dropout(0.3)(x3)\n",
    "    x3 = layers.Dense(64, activation='relu')(x3)\n",
    "    \n",
    "    # איחוד\n",
    "    combined = layers.Concatenate()([x1, x2, x3])\n",
    "    combined = layers.Dense(512, activation='relu')(combined)\n",
    "    combined = layers.Dropout(0.5)(combined)\n",
    "    combined = layers.Dense(256, activation='relu')(combined)\n",
    "    combined = layers.Dropout(0.3)(combined)\n",
    "    \n",
    "    output = layers.Dense(num_classes, activation='softmax')(combined)\n",
    "    \n",
    "    model = keras.Model(inputs=[spectrogram_input, fft_input, time_input], outputs=output)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9257ab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_advanced_model():\n",
    "    \"\"\"אימון מודל מתקדם\"\"\"\n",
    "    \n",
    "    print(\"\\n🔄 שלב 2: אימון מודל מתקדם\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # טעינת נתונים\n",
    "    data_dict, labels_dict = load_geophone_data()\n",
    "    \n",
    "    # הכנת מאפיינים מתקדמים\n",
    "    spectrograms, fft_features, time_features, labels = prepare_advanced_data(data_dict, labels_dict)\n",
    "    \n",
    "    print(f\"✅ נוצרו {len(spectrograms)} ספקטוגרמות מתקדמות\")\n",
    "    print(f\"📊 צורת ספקטוגרמה: {spectrograms[0].shape}\")\n",
    "    \n",
    "    # קידוד תוויות\n",
    "    label_encoder = LabelEncoder()\n",
    "    labels_encoded = label_encoder.fit_transform(labels)\n",
    "    labels_categorical = tf.keras.utils.to_categorical(labels_encoded)\n",
    "    \n",
    "    # נורמליזציה\n",
    "    scaler_fft = StandardScaler()\n",
    "    scaler_time = StandardScaler()\n",
    "    \n",
    "    fft_features_normalized = scaler_fft.fit_transform(fft_features)\n",
    "    time_features_normalized = scaler_time.fit_transform(time_features)\n",
    "    \n",
    "    # חלוקת נתונים\n",
    "    (X_spec_train, X_spec_test, \n",
    "     X_fft_train, X_fft_test, \n",
    "     X_time_train, X_time_test, \n",
    "     y_train, y_test) = train_test_split(\n",
    "        spectrograms, fft_features_normalized, time_features_normalized, labels_categorical,\n",
    "        test_size=0.2, random_state=42, stratify=labels_encoded\n",
    "    )\n",
    "    \n",
    "    # נורמליזציה של ספקטוגרמות\n",
    "    X_spec_train = X_spec_train / 255.0\n",
    "    X_spec_test = X_spec_test / 255.0\n",
    "    \n",
    "    if len(X_spec_train.shape) == 3:\n",
    "        X_spec_train = np.expand_dims(X_spec_train, -1)\n",
    "        X_spec_test = np.expand_dims(X_spec_test, -1)\n",
    "    \n",
    "    print(f\"📈 נתוני אימון מתקדמים: ספקטוגרמות {X_spec_train.shape}\")\n",
    "    \n",
    "    # בניית מודל\n",
    "    print(\"\\n🏗️ בניית מודל מתקדם...\")\n",
    "    model = create_advanced_model(\n",
    "        X_spec_train[0].shape, \n",
    "        X_fft_train.shape[1], \n",
    "        X_time_train.shape[1], \n",
    "        len(label_encoder.classes_)\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    print(\"📋 סיכום מודל מתקדם:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # אימון\n",
    "    print(\"\\n🎯 אימון מודל מתקדם...\")\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(patience=15, restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=7)\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        [X_spec_train, X_fft_train, X_time_train], y_train,\n",
    "        batch_size=32,\n",
    "        epochs=100,\n",
    "        validation_split=0.2,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # הערכה\n",
    "    print(\"\\n📊 הערכת מודל מתקדם...\")\n",
    "    test_loss, test_accuracy = model.evaluate(\n",
    "        [X_spec_test, X_fft_test, X_time_test], y_test, verbose=0\n",
    "    )\n",
    "    print(f\"🎯 דיוק מודל מתקדם: {test_accuracy:.4f}\")\n",
    "    \n",
    "    # תחזיות\n",
    "    y_pred = model.predict([X_spec_test, X_fft_test, X_time_test], verbose=0)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_test_classes = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    print(\"\\n📈 דוח ביצועים - מודל מתקדם:\")\n",
    "    print(classification_report(\n",
    "        y_test_classes, y_pred_classes, \n",
    "        target_names=label_encoder.classes_\n",
    "    ))\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'history': history,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'label_encoder': label_encoder,\n",
    "        'predictions': (y_test_classes, y_pred_classes),\n",
    "        'type': 'advanced'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0867afbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_results(results_list):\n",
    "    \"\"\"השוואת תוצאות המודלים השונים\"\"\"\n",
    "    \n",
    "    print(\"\\n🏆 השוואת תוצאות\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # יצירת טבלת השוואה\n",
    "    comparison_data = []\n",
    "    for result in results_list:\n",
    "        if result:\n",
    "            comparison_data.append({\n",
    "                'מודל': result['type'],\n",
    "                'דיוק': f\"{result['test_accuracy']:.4f}\",\n",
    "                'דיוק %': f\"{result['test_accuracy']*100:.2f}%\"\n",
    "            })\n",
    "    \n",
    "    df_comparison = pd.DataFrame(comparison_data)\n",
    "    print(df_comparison.to_string(index=False))\n",
    "    \n",
    "    # גרף השוואה\n",
    "    if len(comparison_data) > 1:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        models = [item['מודל'] for item in comparison_data]\n",
    "        accuracies = [float(item['דיוק']) for item in comparison_data]\n",
    "        \n",
    "        bars = plt.bar(models, accuracies, color=['skyblue', 'lightgreen', 'orange'][:len(models)])\n",
    "        plt.title('השוואת דיוק המודלים השונים', fontsize=16, fontweight='bold')\n",
    "        plt.ylabel('דיוק')\n",
    "        plt.xlabel('סוג מודל')\n",
    "        plt.ylim(0, 1)\n",
    "        \n",
    "        # הוספת ערכים על העמודות\n",
    "        for bar, acc in zip(bars, accuracies):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                    f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # המלצות\n",
    "    print(\"\\n💡 מסקנות והמלצות:\")\n",
    "    if len(comparison_data) > 1:\n",
    "        best_model = max(comparison_data, key=lambda x: float(x['דיוק']))\n",
    "        print(f\"🥇 המודל הטוב ביותר: {best_model['מודל']} עם דיוק של {best_model['דיוק %']}\")\n",
    "        \n",
    "        worst_model = min(comparison_data, key=lambda x: float(x['דיוק']))\n",
    "        improvement = (float(best_model['דיוק']) - float(worst_model['דיוק'])) * 100\n",
    "        print(f\"📈 שיפור של {improvement:.2f}% בין המודל הגרוע ביותר לטוב ביותר\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0150a73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_comparison():\n",
    "    \"\"\"הרצת השוואה מלאה בין הגישות\"\"\"\n",
    "    \n",
    "    print(\"🚀 התחלת השוואה מקיפה - נתונים גולמיים vs מתקדם\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # שלב 1: מודל נתונים גולמיים 2D\n",
    "    print(\"\\n1️⃣ אימון מודל CNN 2D על נתונים גולמיים...\")\n",
    "    try:\n",
    "        result_raw_2d = train_raw_model(model_type='2d')\n",
    "        results.append(result_raw_2d)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ שגיאה במודל גולמי 2D: {e}\")\n",
    "    \n",
    "    # שלב 2: מודל נתונים גולמיים 1D\n",
    "    print(\"\\n2️⃣ אימון מודל CNN 1D על נתונים גולמיים...\")\n",
    "    try:\n",
    "        result_raw_1d = train_raw_model(model_type='1d')\n",
    "        results.append(result_raw_1d)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ שגיאה במודל גולמי 1D: {e}\")\n",
    "    \n",
    "    # שלב 3: מודל מתקדם\n",
    "    print(\"\\n3️⃣ אימון מודל מתקדם...\")\n",
    "    try:\n",
    "        result_advanced = train_advanced_model()\n",
    "        results.append(result_advanced)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ שגיאה במודל מתקדם: {e}\")\n",
    "    \n",
    "    # השוואת תוצאות\n",
    "    print(\"\\n🔍 השוואת כל התוצאות...\")\n",
    "    compare_results(results)\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5a8c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_comparison_detailed(results_list):\n",
    "    \"\"\"הצגת השוואה מפורטת של המודלים\"\"\"\n",
    "    \n",
    "    if len(results_list) < 2:\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('השוואה מפורטת בין המודלים', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # גרף 1: דיוק\n",
    "    axes[0, 0].bar([r['type'] for r in results_list if r], \n",
    "                   [r['test_accuracy'] for r in results_list if r],\n",
    "                   color=['lightblue', 'lightgreen', 'orange'])\n",
    "    axes[0, 0].set_title('דיוק המודלים')\n",
    "    axes[0, 0].set_ylabel('דיוק')\n",
    "    axes[0, 0].set_ylim(0, 1)\n",
    "    \n",
    "    # גרף 2: היסטוריית אימון (אם יש)\n",
    "    for i, result in enumerate(results_list):\n",
    "        if result and 'history' in result:\n",
    "            history = result['history']\n",
    "            if 'accuracy' in history.history:\n",
    "                axes[0, 1].plot(history.history['accuracy'], \n",
    "                              label=f\"{result['type']} - אימון\", linewidth=2)\n",
    "                if 'val_accuracy' in history.history:\n",
    "                    axes[0, 1].plot(history.history['val_accuracy'], \n",
    "                                  label=f\"{result['type']} - ולידציה\", \n",
    "                                  linestyle='--', linewidth=2)\n",
    "    \n",
    "    axes[0, 1].set_title('התקדמות הדיוק במהלך האימון')\n",
    "    axes[0, 1].set_xlabel('אפוק')\n",
    "    axes[0, 1].set_ylabel('דיוק')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # גרף 3: מטריצות בלבול\n",
    "    for i, result in enumerate(results_list[:2]):  # רק 2 ראשונים\n",
    "        if result and 'predictions' in result:\n",
    "            y_true, y_pred = result['predictions']\n",
    "            cm = confusion_matrix(y_true, y_pred)\n",
    "            \n",
    "            im = axes[1, i].imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "            axes[1, i].set_title(f'מטריצת בלבול - {result[\"type\"]}')\n",
    "            \n",
    "            # הוספת מספרים\n",
    "            thresh = cm.max() / 2.\n",
    "            for j in range(cm.shape[0]):\n",
    "                for k in range(cm.shape[1]):\n",
    "                    axes[1, i].text(k, j, format(cm[j, k], 'd'),\n",
    "                                  ha=\"center\", va=\"center\",\n",
    "                                  color=\"white\" if cm[j, k] > thresh else \"black\")\n",
    "    \n",
    "    # הסתרת גרף רביעי אם אין צורך\n",
    "    if len(results_list) < 3:\n",
    "        axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5950d52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_raw_data_samples():\n",
    "    \"\"\"הצגת דוגמאות מהנתונים הגולמיים\"\"\"\n",
    "    \n",
    "    print(\"📊 הצגת דוגמאות מהנתונים הגולמיים...\")\n",
    "    \n",
    "    try:\n",
    "        data_dict, labels_dict = load_geophone_data()\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        fig.suptitle('דוגמאות מהנתונים הגולמיים (2000 דגימות ראשונות)', fontsize=16)\n",
    "        \n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, (filename, signal_data) in enumerate(data_dict.items()):\n",
    "            if i >= 4:\n",
    "                break\n",
    "            \n",
    "            # הצגת 3 חיישנים ראשונים\n",
    "            sample_data = signal_data[:2000, :min(3, signal_data.shape[1])]\n",
    "            \n",
    "            for j in range(sample_data.shape[1]):\n",
    "                axes[i].plot(sample_data[:, j], \n",
    "                           label=f'חיישן {j+1}', linewidth=1)\n",
    "            \n",
    "            axes[i].set_title(f'{labels_dict[filename]} - {filename}')\n",
    "            axes[i].set_xlabel('זמן (דגימות)')\n",
    "            axes[i].set_ylabel('אמפליטודה')\n",
    "            axes[i].legend()\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "            \n",
    "            # סטטיסטיקות\n",
    "            mean_val = np.mean(np.abs(sample_data))\n",
    "            std_val = np.std(sample_data)\n",
    "            axes[i].text(0.02, 0.98, f'ממוצע מוחלט: {mean_val:.4f}\\nסטיית תקן: {std_val:.4f}', \n",
    "                        transform=axes[i].transAxes, verticalalignment='top',\n",
    "                        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"שגיאה בהצגת נתונים גולמיים: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864bdb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data_preprocessing_comparison():\n",
    "    \"\"\"השוואה בין נתונים גולמיים למעובדים\"\"\"\n",
    "    \n",
    "    print(\"🔬 השוואה בין עיבוד גולמי למתקדם...\")\n",
    "    \n",
    "    try:\n",
    "        data_dict, labels_dict = load_geophone_data()\n",
    "        \n",
    "        # לקיחת דגימה מצעדי אדם\n",
    "        man_data = None\n",
    "        for filename, signal_data in data_dict.items():\n",
    "            if 'man' in filename.lower():\n",
    "                man_data = signal_data[:2000]  # 2 שניות\n",
    "                break\n",
    "        \n",
    "        if man_data is None:\n",
    "            print(\"❌ לא נמצא קובץ צעדי אדם\")\n",
    "            return\n",
    "        \n",
    "        # עיבוד מתקדם\n",
    "        extractor = GeophoneFeatureExtractor()\n",
    "        mel_spec = extractor.extract_mel_spectrogram(man_data, channel=0)\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        fig.suptitle('השוואה: נתונים גולמיים vs מעובדים', fontsize=16)\n",
    "        \n",
    "        # נתונים גולמיים - חיישן ראשון\n",
    "        axes[0, 0].plot(man_data[:, 0])\n",
    "        axes[0, 0].set_title('נתונים גולמיים - חיישן 1')\n",
    "        axes[0, 0].set_xlabel('זמן (דגימות)')\n",
    "        axes[0, 0].set_ylabel('אמפליטודה')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # FFT של הנתונים הגולמיים\n",
    "        fft_vals = fft(man_data[:, 0])\n",
    "        freqs = fftfreq(len(man_data), 1/1000)\n",
    "        axes[0, 1].plot(freqs[:len(freqs)//2], np.abs(fft_vals[:len(fft_vals)//2]))\n",
    "        axes[0, 1].set_title('FFT של הנתונים הגולמיים')\n",
    "        axes[0, 1].set_xlabel('תדר (הרץ)')\n",
    "        axes[0, 1].set_ylabel('עוצמה')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # ספקטוגרמה מתקדמת\n",
    "        librosa.display.specshow(mel_spec, sr=1000, hop_length=512, \n",
    "                                x_axis='time', y_axis='mel', ax=axes[1, 0])\n",
    "        axes[1, 0].set_title('מל-ספקטוגרמה מתקדמת')\n",
    "        \n",
    "        # השוואת מאפיינים\n",
    "        fft_features = extractor.extract_fft_features(man_data)\n",
    "        time_features = extractor.extract_time_domain_features(man_data)\n",
    "        \n",
    "        axes[1, 1].bar(['FFT Features', 'Time Features'], \n",
    "                      [len(fft_features), len(time_features)],\n",
    "                      color=['lightblue', 'lightgreen'])\n",
    "        axes[1, 1].set_title('מספר מאפיינים מחולצים')\n",
    "        axes[1, 1].set_ylabel('מספר מאפיינים')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"📊 מספר מאפייני FFT: {len(fft_features)}\")\n",
    "        print(f\"⏰ מספר מאפיינים בזמן: {len(time_features)}\")\n",
    "        print(f\"🎨 צורת ספקטוגרמה: {mel_spec.shape}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"שגיאה בהשוואת עיבוד: {e}\")\n",
    "\n",
    "def generate_improvement_recommendations(results_list):\n",
    "    \"\"\"יצירת המלצות לשיפור הביצועים\"\"\"\n",
    "    \n",
    "    print(\"\\n🎯 המלצות לשיפור הביצועים\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if not results_list:\n",
    "        print(\"❌ אין תוצאות לניתוח\")\n",
    "        return\n",
    "    \n",
    "    # מציאת המודל הטוב ביותר\n",
    "    best_result = max([r for r in results_list if r], key=lambda x: x['test_accuracy'])\n",
    "    worst_result = min([r for r in results_list if r], key=lambda x: x['test_accuracy'])\n",
    "    \n",
    "    print(f\"🏆 המודל הטוב ביותר: {best_result['type']} ({best_result['test_accuracy']:.4f})\")\n",
    "    print(f\"📉 המודל הנמוך ביותר: {worst_result['type']} ({worst_result['test_accuracy']:.4f})\")\n",
    "    \n",
    "    improvement_gap = best_result['test_accuracy'] - worst_result['test_accuracy']\n",
    "    print(f\"📈 פער שיפור: {improvement_gap:.4f} ({improvement_gap*100:.2f}%)\")\n",
    "    \n",
    "    print(\"\\n💡 המלצות ספציפיות:\")\n",
    "    \n",
    "    # המלצות על בסיס התוצאות\n",
    "    if best_result['test_accuracy'] < 0.7:\n",
    "        print(\"🔴 דיוק נמוך - המלצות חירום:\")\n",
    "        print(\"   • בדוק איכות הנתונים ונקה רעש\")\n",
    "        print(\"   • הגדל את מקבץ הנתונים\")\n",
    "        print(\"   • נסה תכונות נוספות (MFCC, wavelet)\")\n",
    "        print(\"   • שקול data augmentation\")\n",
    "    \n",
    "    elif best_result['test_accuracy'] < 0.85:\n",
    "        print(\"🟡 דיוק בינוני - המלצות לשיפור:\")\n",
    "        print(\"   • כוונן היפר-פרמטרים\")\n",
    "        print(\"   • נסה ארכיטקטורות שונות\")\n",
    "        print(\"   • הוסף regularization\")\n",
    "        print(\"   • שפר את איכות המאפיינים\")\n",
    "    \n",
    "    else:\n",
    "        print(\"🟢 דיוק טוב - המלצות לאופטימיזציה:\")\n",
    "        print(\"   • אופטימיזציה של מהירות המודל\")\n",
    "        print(\"   • בדיקת robustness על נתונים חדשים\")\n",
    "        print(\"   • deploy ובדיקה בסביבה אמיתית\")\n",
    "    \n",
    "    print(\"\\n🔧 המלצות טכניות כלליות:\")\n",
    "    print(\"   • נסה ensemble של מספר מודלים\")\n",
    "    print(\"   • שקול transfer learning מתחומים דומים\")\n",
    "    print(\"   • בצע cross-validation מקיף\")\n",
    "    print(\"   • הוסף המשך ניטור ביצועים\")\n",
    "    \n",
    "    print(\"\\n📊 המלצות לנתונים:\")\n",
    "    print(\"   • אסוף נתונים נוספים במגוון תנאים\")\n",
    "    print(\"   • שפר את איכות התוויות\")\n",
    "    print(\"   • הוסף קטגוריות נוספות אם רלוונטי\")\n",
    "    print(\"   • בדוק איזון בין הקטגוריות\")\n",
    "\n",
    "# הרצת הפרויקט המלא\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🚀 פרויקט זיהוי צעדי אדם - השוואה מקיפה\")\n",
    "    print(\"מנתונים גולמיים לעיבוד מתקדם\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # הצגת דוגמאות מהנתונים\n",
    "    print(\"\\n📊 הצגת דוגמאות מהנתונים הגולמיים...\")\n",
    "    visualize_raw_data_samples()\n",
    "    \n",
    "    # השוואת עיבוד נתונים\n",
    "    print(\"\\n🔬 השוואת שיטות עיבוד...\")\n",
    "    show_data_preprocessing_comparison()\n",
    "    \n",
    "    # הרצת השוואה מלאה\n",
    "    print(\"\\n🏃‍♂️ הרצת השוואה מלאה...\")\n",
    "    results = run_full_comparison()\n",
    "    \n",
    "    # ויזואליזציה מתקדמת\n",
    "    if results:\n",
    "        print(\"\\n📈 ויזואליזציה מתקדמת...\")\n",
    "        plot_model_comparison_detailed(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
